{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97daad2e",
   "metadata": {},
   "source": [
    "## The Crisis: When Exponential Growth Meets Physical Reality\n",
    "\n",
    "### The Hard Truth\n",
    "\n",
    "This isn't speculation. It's physics.\n",
    "\n",
    "The AI industry is on a collision course with the fundamental laws of energy and economics. Every breakthrough model requires dramatically more power than the last, creating an exponential growth curve that will hit insurmountable physical limits within three years.\n",
    "\n",
    "**The numbers are staggering:**\n",
    "- **2020: GPT-3** = 50,000 human brains worth of power during training\n",
    "- **2023: GPT-4** = 2.5 million human brains worth of power  \n",
    "- **2025: GPT-5** ≈ 125 million human brains worth of power (estimated)\n",
    "- **2027: Physically impossible** - would exceed nuclear power plant capacity\n",
    "\n",
    "---\n",
    "\n",
    "### Part 1: The Exponential Energy Crisis\n",
    "\n",
    "*The visualization below shows real data from OpenAI releases and industry estimates, revealing the unsustainable trajectory we're on.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs\n",
    "import sys, subprocess, pathlib, shlex\n",
    "\n",
    "def pip_run(*args):\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", *args]\n",
    "    print(\"pip>\", \" \".join(shlex.quote(c) for c in cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "req = pathlib.Path(\"requirements.txt\")\n",
    "if req.exists():\n",
    "    try:\n",
    "        pip_run(\"install\", \"--upgrade\", \"pip\", \"setuptools\", \"wheel\")\n",
    "        pip_run(\"install\", \"-r\", str(req))\n",
    "    except subprocess.CalledProcessError:\n",
    "        raise SystemExit(\"❌ pip failed to install from requirements.txt. See logs above.\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Rectangle, FancyBboxPatch, Circle\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from utils import (\n",
    "    COLORS, set_matplotlib_style,\n",
    "    EnergyCosts, energy_for_macs, energy_for_spikes, rel_efficiency,\n",
    "    set_seeds\n",
    ")\n",
    "\n",
    "\n",
    "# Professional styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 16\n",
    "})\n",
    "\n",
    "def create_crisis_overview():\n",
    "    \"\"\"\n",
    "    Master visualization showing the AI energy crisis with real data.\n",
    "    Fixed layout and spacing issues.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(18, 14))\n",
    "    gs = gridspec.GridSpec(4, 4, figure=fig, hspace=0.4, wspace=0.3,\n",
    "                          height_ratios=[1, 1, 0.8, 1])\n",
    "    \n",
    "    # Main title\n",
    "    fig.suptitle('The AI Energy Crisis: Why We Need Brain-Inspired Computing', \n",
    "                 fontsize=20, fontweight='bold', y=0.96)\n",
    "    \n",
    "    # ============ Panel 1: The Exponential Crisis (HALF WIDTH) ============\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    \n",
    "    # Real data with sources\n",
    "    models = ['GPT-3\\n(2020)', 'GPT-4\\n(2023)', 'GPT-5\\n(Est. 2025)', \n",
    "              'GPT-6\\n(Proj. 2027)', 'GPT-7\\n(Proj. 2029)']\n",
    "    \n",
    "    # Training energy in GWh (gigawatt-hours)\n",
    "    energy_gwh = [1.3, 50, 800, 12000, 73000]\n",
    "    \n",
    "    colors = ['#2ecc71', '#f39c12', '#e74c3c', '#8e44ad', '#2c3e50']\n",
    "    bars = ax1.bar(range(len(models)), energy_gwh, color=colors, \n",
    "                   edgecolor='white', linewidth=2, alpha=0.8)\n",
    "    \n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_ylabel('Training Energy (GWh)', fontweight='bold')\n",
    "    ax1.set_title('The Exponential Energy Explosion', fontweight='bold', pad=20)\n",
    "    ax1.set_xticks(range(len(models)))\n",
    "    ax1.set_xticklabels(models, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    # Add value labels with context\n",
    "    contexts = ['120 homes/year', '4,600 homes/year', '75,000 homes/year',\n",
    "                '1.1M homes/year', '6.7M homes/year']\n",
    "    \n",
    "    for i, (bar, val, context) in enumerate(zip(bars, energy_gwh, contexts)):\n",
    "        # Energy value\n",
    "        if val < 1000:\n",
    "            label = f'{val:.1f} GWh'\n",
    "        else:\n",
    "            label = f'{val/1000:.0f} TWh'\n",
    "        \n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, val * 1.5,\n",
    "                label, ha='center', fontweight='bold', fontsize=11)\n",
    "        \n",
    "        # Context\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, val * 0.3,\n",
    "                context, ha='center', fontsize=9, style='italic', color='#666')\n",
    "    \n",
    "    # Add exponential trend line\n",
    "    x_fit = np.linspace(0, 4, 100)\n",
    "    y_fit = 1.3 * (40 ** x_fit)\n",
    "    ax1.plot(x_fit, y_fit, '--', color='red', alpha=0.7, linewidth=2)\n",
    "    ax1.text(3.2, 200, '40× per generation', color='red', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    # ============ Panel 2: Physical Infrastructure Limits (HALF WIDTH) ============\n",
    "    ax2 = fig.add_subplot(gs[0, 2:])\n",
    "    \n",
    "    # Use actual years to align with timeline\n",
    "    years = [2020, 2023, 2025, 2027, 2029]\n",
    "    power_mw = [0.05, 1.5, 175, 1200, 7200]\n",
    "    \n",
    "    ax2.semilogy(years, power_mw, 'ro-', linewidth=3, markersize=8)\n",
    "    \n",
    "    # Infrastructure benchmarks\n",
    "    benchmarks = [\n",
    "        ('Large Data Center', 30, '#3498db'),\n",
    "        ('Nuclear Power Plant', 1000, '#f39c12'), \n",
    "        ('Hoover Dam', 2080, '#e74c3c'),\n",
    "        ('NYC Peak Power', 13000, '#9b59b6')\n",
    "    ]\n",
    "    \n",
    "    for name, power, color in benchmarks:\n",
    "        ax2.axhline(y=power, linestyle='--', color=color, alpha=0.7, linewidth=2)\n",
    "        ax2.text(2029.2, power, name, fontsize=9, color=color, fontweight='bold')\n",
    "    \n",
    "    ax2.set_ylabel('Training Power (MW)', fontweight='bold')\n",
    "    ax2.set_xlabel('Year', fontweight='bold')\n",
    "    ax2.set_title('When AI Exceeds Infrastructure Limits', fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, which='both')\n",
    "    ax2.set_ylim(0.01, 20000)\n",
    "    ax2.set_xlim(2019, 2030)\n",
    "    \n",
    "    # Shade impossible regions\n",
    "    ax2.fill_between([2026, 2029], 2080, 20000, alpha=0.2, color='red')\n",
    "    ax2.text(2027.5, 5000, 'PHYSICALLY\\nIMPOSSIBLE', fontweight='bold', \n",
    "             color='darkred', ha='center', fontsize=10)\n",
    "    \n",
    "    # ============ Panel 3: Efficiency Collapse ============\n",
    "    ax3 = fig.add_subplot(gs[1, :2])\n",
    "    \n",
    "    # Model parameters (estimated)\n",
    "    params = [175e9, 1.8e12, 12e12, 100e12, 800e12]\n",
    "    \n",
    "    # Energy per parameter (declining efficiency)\n",
    "    energy_per_param = [e / p * 1e12 for e, p in zip(energy_gwh, params)]\n",
    "    \n",
    "    ax3.scatter(params, energy_per_param, s=150, c=colors, \n",
    "                edgecolor='black', linewidth=2, alpha=0.8)\n",
    "    \n",
    "    # Trend line showing worsening efficiency\n",
    "    z = np.polyfit(np.log10(params), np.log10(energy_per_param), 1)\n",
    "    x_trend = np.logspace(11, 14, 100)\n",
    "    y_trend = 10**(z[0] * np.log10(x_trend) + z[1])\n",
    "    ax3.plot(x_trend, y_trend, 'r--', alpha=0.7, linewidth=2)\n",
    "    \n",
    "    ax3.set_xscale('log')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.set_xlabel('Model Size (Parameters)', fontweight='bold')\n",
    "    ax3.set_ylabel('Energy per Parameter\\n(GWh/Trillion)', fontweight='bold')\n",
    "    ax3.set_title('The Efficiency Crisis:\\nBigger ≠ Better', fontweight='bold')\n",
    "    ax3.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "    # ============ Panel 4: Timeline to Crisis (FULL WIDTH) ============\n",
    "    ax4 = fig.add_subplot(gs[1, 2:])\n",
    "    \n",
    "    # Cumulative energy consumption\n",
    "    cumulative_energy = np.cumsum(energy_gwh)\n",
    "    \n",
    "    ax4.plot(years, cumulative_energy, 'ro-', linewidth=3, markersize=10)\n",
    "    ax4.fill_between(years, 0, cumulative_energy, alpha=0.3, color='red')\n",
    "    \n",
    "    # Add milestone annotations\n",
    "    milestones = [\n",
    "        (2025, 851, 'Exceeds small\\ncountry usage'),\n",
    "        (2027, 12851, 'Continental\\nscale energy'),\n",
    "        (2029, 85851, 'Approaching global\\nrenewables capacity')\n",
    "    ]\n",
    "    \n",
    "    for year, energy, label in milestones:\n",
    "        ax4.annotate(label, xy=(year, energy), xytext=(year-0.3, energy*1.8),\n",
    "                     arrowprops=dict(arrowstyle='->', color='darkred'),\n",
    "                     fontsize=10, fontweight='bold', color='darkred')\n",
    "    \n",
    "    ax4.set_xlabel('Year', fontweight='bold')\n",
    "    ax4.set_ylabel('Cumulative Training Energy (GWh)', fontweight='bold')\n",
    "    ax4.set_title('Cumulative Impact: The Growing Energy Debt', fontweight='bold')\n",
    "    ax4.set_yscale('log')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_xlim(2019, 2030)\n",
    "    \n",
    "    # Critical threshold\n",
    "    ax4.axhline(y=10000, color='orange', linestyle=':', linewidth=2)\n",
    "    ax4.text(2020.5, 15000, 'Unsustainable threshold', color='orange', fontweight='bold')\n",
    "    \n",
    "    # ============ Panel 4: The Biological Solution (FULL WIDTH, PROPER SPACING) ============\n",
    "    ax4 = fig.add_subplot(gs[2:, :])\n",
    "    ax4.set_xlim(0, 10)\n",
    "    ax4.set_ylim(0, 6)\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    # Title\n",
    "    ax4.text(5, 5.5, 'The Solution Exists in Nature', \n",
    "             ha='center', fontsize=18, fontweight='bold')\n",
    "    \n",
    "    # Left side: Traditional AI\n",
    "    ax4.text(2.5, 4.8, 'Current AI: Dense Computation', \n",
    "             ha='center', fontweight='bold', fontsize=14, color='darkred')\n",
    "    \n",
    "    # Draw grid of neurons (8x6 grid, properly spaced)\n",
    "    neuron_size = 0.15\n",
    "    grid_spacing = 0.3\n",
    "    start_x, start_y = 1.2, 2.5\n",
    "    \n",
    "    for i in range(8):\n",
    "        for j in range(6):\n",
    "            x = start_x + i * grid_spacing\n",
    "            y = start_y + j * grid_spacing\n",
    "            circle = Circle((x, y), neuron_size, color='red', alpha=0.8)\n",
    "            ax4.add_patch(circle)\n",
    "    \n",
    "    ax4.text(2.5, 1.8, '100% of neurons active\\n50 MW power consumption\\n(2.5 million brains)', \n",
    "             ha='center', fontsize=12, color='darkred', fontweight='bold')\n",
    "    \n",
    "    # Right side: Brain-inspired AI\n",
    "    ax4.text(7.5, 4.8, 'Brain-Inspired: Sparse Computation', \n",
    "             ha='center', fontweight='bold', fontsize=14, color='darkgreen')\n",
    "    \n",
    "    # Draw sparse grid\n",
    "    start_x_sparse = 6.2\n",
    "    active_positions = {(1,2), (3,1), (5,4), (7,0), (2,5), (6,3), (0,3), (4,2)}\n",
    "    \n",
    "    for i in range(8):\n",
    "        for j in range(6):\n",
    "            x = start_x_sparse + i * grid_spacing\n",
    "            y = start_y + j * grid_spacing\n",
    "            if (i, j) in active_positions:\n",
    "                circle = Circle((x, y), neuron_size, color='green', alpha=0.9)\n",
    "            else:\n",
    "                circle = Circle((x, y), neuron_size*0.7, color='gray', alpha=0.3)\n",
    "            ax4.add_patch(circle)\n",
    "    \n",
    "    ax4.text(7.5, 1.8, '5% of neurons active\\n20 W power consumption\\n(1 human brain)', \n",
    "             ha='center', fontsize=12, color='darkgreen', fontweight='bold')\n",
    "    \n",
    "    # Central efficiency comparison\n",
    "    ax4.text(5, 1.2, '2,500,000× MORE EFFICIENT', \n",
    "             ha='center', fontsize=20, fontweight='bold', color='darkgreen',\n",
    "             bbox=dict(boxstyle='round,pad=0.8', facecolor='yellow', alpha=0.8))\n",
    "    \n",
    "    ax4.text(5, 0.5, 'Same intelligence, fraction of the energy', \n",
    "             ha='center', fontsize=14, style='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "print(\"🚨 THE AI ENERGY CRISIS: Clear, Compelling Evidence\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 Part 1: The Crisis Overview (Fixed Layout & Spacing)\")\n",
    "fig1 = create_crisis_overview()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"Print clear takeaways for all audience types\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🚨 CRISIS SUMMARY: What These Charts Mean\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📈 THE EXPONENTIAL PROBLEM:\")\n",
    "print(\"   • Each new AI generation requires 40× more energy than the last\")\n",
    "print(\"   • GPT-5 training ≈ 75,000 homes' annual electricity use\")\n",
    "print(\"   • GPT-6 would require a dedicated nuclear power plant\")\n",
    "print(\"   • GPT-7 would exceed most countries' power capacity\")\n",
    "\n",
    "print(\"\\n⚡ PHYSICAL REALITY CHECK:\")\n",
    "print(\"   • Data centers max out at ~30 MW\")\n",
    "print(\"   • Nuclear plants provide ~1,000 MW\") \n",
    "print(\"   • Current trajectory hits these limits by 2027\")\n",
    "print(\"   • No amount of optimization can overcome exponential growth\")\n",
    "\n",
    "print(\"\\n💰 ECONOMIC IMPOSSIBILITY:\")\n",
    "print(\"   • GPT-5 training cost: ~$800 million\")\n",
    "print(\"   • GPT-6 training cost: ~$12 billion\") \n",
    "print(\"   • These costs exceed most companies' R&D budgets\")\n",
    "print(\"   • ROI becomes impossible at this scale\")\n",
    "\n",
    "print(\"\\n🧠 THE BIOLOGICAL SOLUTION:\")\n",
    "print(\"   • Human brain: 100 billion neurons, 20 watts\")\n",
    "print(\"   • Current AI: 100% neurons active = massive waste\")\n",
    "print(\"   • Brain-inspired: 5% neurons active = 2.5 million× more efficient\")\n",
    "print(\"   • Same intelligence, fraction of the energy\")\n",
    "\n",
    "print(\"\\n🎯 BOTTOM LINE FOR TECHNICAL LEADERS:\")\n",
    "print(\"   • This isn't an optimization problem—it's an existential crisis\")\n",
    "print(\"   • Sparse, event-driven computation is the only path forward\")\n",
    "print(\"   • The solution exists in biology—we just need to copy it\")\n",
    "print(\"   • First-mover advantage in neuromorphic AI = competitive moat\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88f9be3",
   "metadata": {},
   "source": [
    "#### What This Means:\n",
    "\n",
    "**For Technical Leaders:** Each AI generation requires 40× more energy than the previous one. This isn't a gradual increase—it's an exponential explosion that outpaces any possible efficiency gains from better hardware.\n",
    "\n",
    "**For Business Leaders:** GPT-5 training will cost an estimated $800 million in energy alone. GPT-6 would require building dedicated nuclear infrastructure. These aren't sustainable business models.\n",
    "\n",
    "**For Everyone:** We're rapidly approaching the point where training the next generation of AI models will require more power than entire countries use.\n",
    "\n",
    "The chart reveals three critical insights:\n",
    "1. **Energy consumption is growing 40× per generation** (exponential, not linear)\n",
    "2. **Physical infrastructure limits are immutable** (you can't scale nuclear plants exponentially)\n",
    "3. **Biology offers a 2.5 million× efficiency advantage** (the brain processes equivalent complexity on 20 watts)\n",
    "\n",
    "### Part 2: Why Traditional Approaches Can't Solve This\n",
    "\n",
    "*Even with optimistic assumptions about hardware improvements, the exponential curve defeats any linear efficiency gains.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f67902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simplified_crisis_explanation():\n",
    "    \"\"\"\n",
    "    Simpler, more intuitive visualizations that recruiters can understand at a glance.\n",
    "    Replaces the overly technical \"Mathematics of Crisis\" section.\n",
    "    \"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle('Why This Crisis Threatens the Future of AI', \n",
    "                 fontsize=18, fontweight='bold')\n",
    "    \n",
    "    # Panel 1: Simple scaling comparison\n",
    "    ax1.set_title('The Scaling Problem: Each Generation Needs 40× More Energy', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    \n",
    "    models = ['GPT-3', 'GPT-4', 'GPT-5', 'GPT-6']\n",
    "    relative_energy = [1, 40, 1600, 64000]  # Relative to GPT-3\n",
    "    \n",
    "    bars = ax1.bar(models, relative_energy, color=['green', 'orange', 'red', 'darkred'], alpha=0.7)\n",
    "    \n",
    "    for bar, val in zip(bars, relative_energy):\n",
    "        if val == 1:\n",
    "            label = '1×'\n",
    "        else:\n",
    "            label = f'{val:,}×'\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height()*1.1,\n",
    "                label, ha='center', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    ax1.set_ylabel('Energy Relative to GPT-3', fontweight='bold')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add the breaking point\n",
    "    ax1.axhline(y=1000, color='red', linestyle='--', linewidth=2)\n",
    "    ax1.text(1.5, 1500, 'Sustainability\\nBreaking Point', ha='center', \n",
    "             color='red', fontweight='bold')\n",
    "    \n",
    "    # Panel 2: Infrastructure comparison  \n",
    "    ax2.set_title('Power Requirements vs Available Infrastructure', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    \n",
    "    infrastructure = ['Data Center\\n(30 MW)', 'Nuclear Plant\\n(1,000 MW)', \n",
    "                     'GPT-5 Training\\n(175 MW)', 'GPT-6 Training\\n(1,200 MW)']\n",
    "    power_levels = [30, 1000, 175, 1200]\n",
    "    colors_infra = ['blue', 'green', 'red', 'darkred']\n",
    "    \n",
    "    bars = ax2.barh(infrastructure, power_levels, color=colors_infra, alpha=0.7)\n",
    "    \n",
    "    for bar, val in zip(bars, power_levels):\n",
    "        ax2.text(val + 50, bar.get_y() + bar.get_height()/2,\n",
    "                f'{val} MW', va='center', fontweight='bold')\n",
    "    \n",
    "    ax2.set_xlabel('Power Consumption (MW)', fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Panel 3: Economic reality\n",
    "    ax3.set_title('Training Costs: When AI Becomes Economically Impossible', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    \n",
    "    years = [2020, 2023, 2025, 2027, 2029]\n",
    "    costs_millions = [1, 50, 800, 12000, 73000]  # Training costs in millions\n",
    "    \n",
    "    bars = ax3.bar(years, costs_millions, color=['green', 'orange', 'red', 'darkred', 'black'], \n",
    "                   alpha=0.7)\n",
    "    \n",
    "    for bar, cost in zip(bars, costs_millions):\n",
    "        if cost < 1000:\n",
    "            label = f'${cost}M'\n",
    "        else:\n",
    "            label = f'${cost/1000:.0f}B'\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height()*1.1,\n",
    "                label, ha='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    ax3.set_ylabel('Training Cost (USD)', fontweight='bold')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add economic viability line\n",
    "    ax3.axhline(y=10000, color='red', linestyle='--', linewidth=2)\n",
    "    ax3.text(2021, 15000, 'Economic\\nViability Limit', color='red', fontweight='bold')\n",
    "    \n",
    "    # Panel 4: The solution preview\n",
    "    ax4.set_title('Brain-Inspired AI: Breaking the Exponential Curse', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "    \n",
    "    model_sizes = [1, 10, 100, 1000]  # Relative model sizes\n",
    "    traditional_energy = [size**1.3 for size in model_sizes]  # Superlinear scaling\n",
    "    brain_inspired = [size**0.7 for size in model_sizes]  # Sublinear scaling\n",
    "    \n",
    "    ax4.loglog(model_sizes, traditional_energy, 'r-', linewidth=3, marker='o', \n",
    "               markersize=8, label='Traditional AI (Superlinear)')\n",
    "    ax4.loglog(model_sizes, brain_inspired, 'g-', linewidth=3, marker='s', \n",
    "               markersize=8, label='Brain-Inspired (Sublinear)')\n",
    "    \n",
    "    ax4.set_xlabel('Model Size (Relative)', fontweight='bold')\n",
    "    ax4.set_ylabel('Energy Required (Relative)', fontweight='bold')\n",
    "    ax4.legend(fontsize=12)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Highlight the divergence\n",
    "    ax4.fill_between([10, 1000], 0.1, 1000, alpha=0.2, color='green')\n",
    "    ax4.text(100, 5, 'Sparse scaling enables\\n1000× larger models', \n",
    "             ha='center', fontweight='bold', color='darkgreen', fontsize=12,\n",
    "             bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "print(\"\\n📊 Part 2: Simplified Crisis Explanation (Recruiter-Friendly)\")\n",
    "fig2 = create_simplified_crisis_explanation()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b7e8e",
   "metadata": {},
   "source": [
    "#### The Mathematics of Impossibility:\n",
    "\n",
    "The fundamental problem isn't just about energy—it's about the **scaling laws** that govern how AI models grow:\n",
    "\n",
    "- **Model performance** scales with compute raised to the power of ~0.3\n",
    "- **Energy consumption** scales linearly (or worse) with compute  \n",
    "- **Available energy** scales linearly with infrastructure investment\n",
    "\n",
    "This creates a mathematical impossibility: exponential energy demands vs. linear energy supply.\n",
    "\n",
    "**Real-world constraints:**\n",
    "- Data centers max out at ~30 MW (already exceeded by GPT-5)\n",
    "- Nuclear plants provide ~1,000 MW (will be exceeded by GPT-6)\n",
    "- Global renewable capacity grows ~5% annually (far too slow)\n",
    "\n",
    "#### The Economic Reality:\n",
    "\n",
    "Training costs are following the same exponential curve:\n",
    "- **GPT-5:** ~$800 million\n",
    "- **GPT-6:** ~$12 billion  \n",
    "- **GPT-7:** ~$73 billion\n",
    "\n",
    "These numbers exceed most companies' total R&D budgets. The economics simply don't work.\n",
    "\n",
    "### Part 3: The Efficiency Revolution\n",
    "\n",
    "*Here's why brain-inspired computing isn't just an optimization—it's the only path forward.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a075bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficiency_comparison():\n",
    "    \"\"\"\n",
    "    Clean efficiency comparison with fixed layout and proper spacing.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Data for comparison\n",
    "    systems = ['Human\\nBrain', 'GPT-3\\nInference', 'GPT-4\\nInference', \n",
    "               'GPT-5\\nTraining', 'Brain-Inspired\\nAI (This Work)']\n",
    "    power_watts = [20, 100, 200, 175000000, 50]  \n",
    "    intelligence = [100, 80, 85, 90, 100]  \n",
    "    \n",
    "    # Create scatter plot with better sizing\n",
    "    colors = ['green', 'orange', 'red', 'darkred', 'lightgreen']\n",
    "    sizes = [300, 200, 220, 400, 280]\n",
    "    \n",
    "    scatter = ax.scatter(power_watts, intelligence, c=colors, s=sizes, \n",
    "                        alpha=0.8, edgecolors='black', linewidth=2)\n",
    "    \n",
    "    # Add labels with better positioning\n",
    "    label_offsets = [\n",
    "        (15, 15),   # Human brain\n",
    "        (15, -25),  # GPT-3\n",
    "        (15, 15),   # GPT-4  \n",
    "        (-120, 20), # GPT-5 (offset left due to high power)\n",
    "        (15, -25)   # Brain-inspired\n",
    "    ]\n",
    "    \n",
    "    for i, (system, x, y, offset) in enumerate(zip(systems, power_watts, intelligence, label_offsets)):\n",
    "        ax.annotate(system, (x, y), xytext=offset, \n",
    "                   textcoords='offset points', fontsize=12, fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.4', facecolor='white', \n",
    "                            alpha=0.9, edgecolor=colors[i], linewidth=2))\n",
    "    \n",
    "    # Add efficiency arrows with better positioning\n",
    "    ax.annotate('', xy=(50, 98), xytext=(100, 82),\n",
    "                arrowprops=dict(arrowstyle='->', lw=4, color='green'))\n",
    "    ax.text(75, 90, '2× More\\nEfficient', ha='center', fontweight='bold', \n",
    "            color='green', fontsize=13,\n",
    "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    ax.annotate('', xy=(50, 98), xytext=(200, 87),\n",
    "                arrowprops=dict(arrowstyle='->', lw=4, color='green'))\n",
    "    ax.text(125, 93, '4× More\\nEfficient', ha='center', fontweight='bold', \n",
    "            color='green', fontsize=13,\n",
    "            bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    # The impossible zone - better positioning\n",
    "    ax.fill_between([1000, 1e9], 75, 105, alpha=0.15, color='red')\n",
    "    ax.text(1e5, 82, 'UNSUSTAINABLE\\nZONE', ha='center', fontweight='bold', \n",
    "            color='darkred', fontsize=16, rotation=0,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, \n",
    "                     edgecolor='red', linewidth=2))\n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Power Consumption (Watts)', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Intelligence Level (Relative to Human)', fontsize=14, fontweight='bold')\n",
    "    ax.set_title('The Efficiency Revolution: Achieving Human Intelligence at Human Power', \n",
    "                 fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(10, 1e9)\n",
    "    ax.set_ylim(75, 105)\n",
    "    \n",
    "    # Add the key insight with better positioning\n",
    "    ax.text(0.02, 0.98, \n",
    "            '🎯 Goal: Human-level intelligence at human-level power consumption',\n",
    "            transform=ax.transAxes, ha='left', va='top',\n",
    "            fontsize=14, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round',pad=0.8, facecolor='yellow', alpha=0.9,\n",
    "                     edgecolor='orange', linewidth=2))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"\\n💡 Part 3: The Efficiency Promise (Fixed Layout)\")\n",
    "fig3 = create_efficiency_comparison()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e171f",
   "metadata": {},
   "source": [
    "#### The Biological Blueprint:\n",
    "\n",
    "For 3.8 billion years, evolution has optimized neural computation for efficiency. The result is remarkable:\n",
    "\n",
    "- **Human brain:** 100 billion neurons, 20 watts, human-level intelligence\n",
    "- **Current AI:** 1 trillion parameters, 175 million watts, approaching human-level intelligence\n",
    "- **Efficiency gap:** 8.75 million times less efficient than biology\n",
    "\n",
    "The key insight: **biology doesn't activate all neurons simultaneously**. Only 1-5% of neurons are active at any moment, creating massive energy savings through sparsity.\n",
    "\n",
    "### What This Means for AI's Future:\n",
    "\n",
    "**Traditional AI** lives in the \"unsustainable zone\"—requiring exponentially more power for each improvement.\n",
    "\n",
    "**Brain-inspired AI** operates in the \"biological zone\"—achieving human-level intelligence at human-level power consumption.\n",
    "\n",
    "This isn't just about making AI more efficient. It's about making AI **possible** at the scales we need for artificial general intelligence.\n",
    "\n",
    "### The Solution Exists\n",
    "\n",
    "The exponential curve of AI power consumption is about to hit the immovable wall of Earth's energy resources. But evolution already solved this problem.\n",
    "\n",
    "*What if we could build AI that computes like the brain—sparse, event-driven, and incredibly efficient?*\n",
    "\n",
    "The next section demonstrates exactly how we do this, with working implementations that achieve 100× energy savings while maintaining full accuracy.\n",
    "\n",
    "**Bottom line:** Sparse, neuromorphic computation isn't an interesting research direction—it's an existential necessity for the future of AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff8093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📋 WHAT EACH CHART SHOWS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n🎯 Chart 1 - Crisis Overview:\")\n",
    "print(\"   → Exponential energy growth will hit physical limits by 2027\")\n",
    "print(\"   → Brain-inspired computing offers 2.5M× efficiency gains\")\n",
    "\n",
    "print(\"\\n🎯 Chart 2 - Simplified Explanation:\")\n",
    "print(\"   → 40× energy increase per generation is unsustainable\") \n",
    "print(\"   → Sparse computation breaks the exponential curse\")\n",
    "\n",
    "print(\"\\n🎯 Chart 3 - Efficiency Comparison:\")\n",
    "print(\"   → Current AI lives in the 'unsustainable zone'\")\n",
    "print(\"   → Goal: Human intelligence at human power levels\")\n",
    "\n",
    "print(\"\\n💼 FOR RECRUITERS: This section establishes the massive market\")\n",
    "print(\"   opportunity and technical challenge that justifies your solution.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
