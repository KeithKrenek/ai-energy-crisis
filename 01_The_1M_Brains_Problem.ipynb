{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3dfbeb",
   "metadata": {},
   "source": [
    "# The Cost of 1 Million Brains\n",
    "### Current AI Implementations Are Inefficient, and Existing Energy Tech Cannot Support Tomorrow's Models\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #9c31e4ff 0%, #292f56 100%); padding: 20px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <h3 style=\"color: white; margin: 0;\">Some Numbers</h3>\n",
    "    <p style=\"color: white; margin: 10px 0;\">GPT-4 consumes <b>1 million times</b> more power than a human brain while approaching similar intelligence levels. This notebook demonstrates why this is unsustainable and previews a solution that achieves <b>10-100× efficiency gains</b> using brain-inspired computing.</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**Brain-Inspired AI Series**  \n",
    "**[Part 1: The Problem]** | [Part 2: Biology →](link) | [Part 3: Crisis →](link) | [Part 4: Solution →](link) | [Part 5: Impact →](link)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f3fcf",
   "metadata": {},
   "source": [
    "## AI Energy Consumption Is Shocking\n",
    "\n",
    "The AI revolution is running into an energy crisis. The staggering efficiency gap between large-scale AI models and the human brain, from their initial \"training\" to continuous operation and even single tasks, is quantified in the table below. This notebook directly confronts this challenge by implementing and analyzing brain-inspired Spiking Neural Networks (SNNs) that prove a viable path toward sustainable AI by achieving a **10-100× reduction** in computational energy without sacrificing accuracy.\n",
    "\n",
    "| Comparison | Metric | GPT-4 | Human Brain | Bottom Line |\n",
    "|---|---|---|---|---|\n",
    "| **Upfront \"Training\"** | Total Energy to Maturity | ~75 GWh<sup>a</sup> | ~4,900 kWh<sup>b</sup> | **>10,000×** more energy for GPT-4's \"childhood\" |\n",
    "| **Operational Power** | Continuous Power Draw | ~20 MW<sup>c</sup> | 20 W | GPT-4 runs on the power of **1 million brains** |\n",
    "| **Task Energy** | Energy for a Single Action | ~1,440 J / query<sup>c</sup> | ~1,200 J / minute | A single query costs more than a minute of thought |\n",
    "\n",
    "<sup>a</sup>Based on scaling laws from GPT-3 (Patterson et al., 2021): 50-100 GWh\n",
    "\n",
    "<sup>b</sup>Accounting for higher power consumption during adolescence: 25W × 22 years × 365.25 days/year × 24 hours/day continuous operation\n",
    "\n",
    "<sup>c</sup>Estimated from datacenter deployments, i.e. query volume and server energy use, which place the likely power consumption in the 14-21 MW range: 2.5 billion queries per day at 0.3 - 0.4 Wh per query divided by 24 hours/day\n",
    "\n",
    "As we will see below, this inefficiency reality of modern AI is approaching an insurmountable wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e4a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib.util\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install using pip\"\"\"\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "def check_and_install(package_name, import_name=None):\n",
    "    \"\"\"Check if installed, if not then install\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    spec = importlib.util.find_spec(import_name)\n",
    "    if spec is None:\n",
    "        print(f\"Installing {package_name}...\")\n",
    "        try:\n",
    "            install_package(package_name)\n",
    "            print(f\"{package_name} installed successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to install {package_name}: {e}\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(\"Setting up environment...\")\n",
    "\n",
    "required_packages = [\n",
    "    # (package_name, import_name)\n",
    "    ('numpy', 'numpy'),\n",
    "    ('matplotlib', 'matplotlib'),\n",
    "    ('torch', 'torch'),\n",
    "    ('torchvision', 'torchvision'),\n",
    "    ('tqdm', 'tqdm'),\n",
    "    ('ipywidgets', 'ipywidgets'),\n",
    "]\n",
    "\n",
    "all_installed = True\n",
    "for package, import_name in required_packages:\n",
    "    if not check_and_install(package, import_name):\n",
    "        all_installed = False\n",
    "\n",
    "if not all_installed:\n",
    "    print(\"\\nSome packages failed to install. Please install manually:\")\n",
    "    print(f\"pip install {' '.join(name for name, _ in required_packages)}\")\n",
    "else:\n",
    "    print(\"Environment setup complete.\")\n",
    "\n",
    "# Imports, config, styling, and device setup\n",
    "print(\"\\nImporting dependencies, configuring styles and device...\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Circle, Rectangle, FancyBboxPatch, FancyArrowPatch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, MaxNLocator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from IPython.display import HTML, display, clear_output\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create directories for outputs\n",
    "Path(\"figures\").mkdir(exist_ok=True)\n",
    "Path(\"models\").mkdir(exist_ok=True)\n",
    "Path(\"data\").mkdir(exist_ok=True)\n",
    "\n",
    "# Define color palette\n",
    "COLORS = {\n",
    "    'primary': '#667eea',      # Purple\n",
    "    'secondary': '#f56565',    # Red  \n",
    "    'success': '#48bb78',      # Green\n",
    "    'warning': '#ed8936',      # Orange\n",
    "    'severe': '#9b59b6',       # Purple\n",
    "    'info': '#4299e1',         # Blue\n",
    "    'dark': '#2d3748',         # Dark gray\n",
    "    'light': '#f7fafc',        # Light gray\n",
    "    'ann': '#e74c3c',          # ANN Red\n",
    "    'snn': '#27ae60',          # SNN Green\n",
    "    'brain': '#3498db',        # Brain Blue\n",
    "    'dark_text': '#34495e'\n",
    "}\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (14, 7),\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': 'white',\n",
    "    'axes.edgecolor': '#CCCCCC',\n",
    "    'axes.linewidth': 1.5,\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.titlepad': 20,\n",
    "    'axes.labelsize': 13,\n",
    "    'axes.labelweight': 'bold',\n",
    "    'axes.labelpad': 10,\n",
    "    'xtick.labelsize': 11,\n",
    "    'ytick.labelsize': 11,\n",
    "    'legend.fontsize': 11,\n",
    "    'legend.frameon': True,\n",
    "    'legend.fancybox': True,\n",
    "    'legend.shadow': True,\n",
    "    'figure.titlesize': 18,\n",
    "    'lines.linewidth': 2.5,\n",
    "    'lines.markersize': 8,\n",
    "    'grid.alpha': 0.3,\n",
    "    'grid.linestyle': '--',\n",
    "    'axes.grid': True,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "plt.rcParams['animation.embed_limit'] = 50.0\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "# Configure device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using device: {device}\")\n",
    "print(f\"{'GPU enabled.' if device.type == 'cuda' else 'Running on CPU (may be slower).'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853585b6",
   "metadata": {},
   "source": [
    "## Part 1: Visualizing the Energy Gap\n",
    "\n",
    "Let's start with energy estimates using numbers measured from real systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e73488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_energy_comparison():\n",
    "    \"\"\"Compare energy consumption of human brain and modern AI systems.\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    systems = ['Human\\nBrain', 'GPT-3\\n(Inference)', 'GPT-4\\n(Inference)', 'GPT-4\\n(Training)', 'GPT-5\\n(Training Est.)']\n",
    "    power_watts = [20, 100, 200, 50_000_000, 175_000_000]\n",
    "    intelligence_relative = [100, 70, 85, 85, 92] # Relative to human = 100\n",
    "    \n",
    "    # Subplot 1: Power Consumption (Log Scale)\n",
    "    colors = [COLORS['brain'], COLORS['warning'], COLORS['secondary'], COLORS['dark'], COLORS['severe']]\n",
    "    bars = ax1.bar(systems, power_watts, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "\n",
    "    for bar, power in zip(bars, power_watts):\n",
    "        height = bar.get_height()\n",
    "        if power < 1000:\n",
    "            label = f'{power}W'\n",
    "        elif power < 1_000_000:\n",
    "            label = f'{power/1000:.0f}kW'\n",
    "        else:\n",
    "            label = f'{power/1_000_000:.0f}MW'\n",
    "        \n",
    "        # Adjust label position for log scale\n",
    "        y_pos = height * 1.8\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., y_pos,\n",
    "                 label, ha='center', va='bottom', fontweight='bold', fontsize=13)\n",
    "    \n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_ylabel('Power Consumption (Watts)')\n",
    "    ax1.set_title('Power Requirements of Human Brain vs AI Models')\n",
    "    ax1.set_ylim([10, 2_000_000_000])\n",
    "    # ax1.set_xlim([-1, 5])\n",
    "    ax1.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    ax1.annotate('8.75 MILLION× more power', \n",
    "                 xy=(4, 175_000_000), xytext=(1.5, 1_000_000_000),\n",
    "                 arrowprops=dict(arrowstyle='-', color='black', lw=1.5),\n",
    "                 fontsize=14, fontweight='bold', color='black',\n",
    "                 bbox=dict(boxstyle='round,pad=0.7', facecolor='yellow', \n",
    "                           edgecolor='black', alpha=0.9))\n",
    "    \n",
    "    # Subplot 2: Efficiency (Intelligence per Watt)\n",
    "    efficiency = [intel/power for intel, power in zip(intelligence_relative, power_watts)]\n",
    "    \n",
    "    bars2 = ax2.bar(systems, efficiency, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    for bar, eff in zip(bars2, efficiency):\n",
    "        height = bar.get_height()\n",
    "        if eff >= 0.001:\n",
    "            label = f'{eff:.3f}'\n",
    "        else:\n",
    "            label = f'{eff:.2e}'\n",
    "        y_pos = height * 1.5\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., y_pos,\n",
    "                 label, ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "    \n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_ylabel('Intelligence per Watt (Efficiency Score)')\n",
    "    ax2.set_title('Computational Efficiency Comparison')\n",
    "    ax2.set_ylim([1e-10, 10])\n",
    "    ax2.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    # Add reference line for brain efficiency\n",
    "    ax2.axhline(y=efficiency[0], color='green', linestyle='--', alpha=0.5, linewidth=2.5)\n",
    "    ax2.text(4.5, efficiency[0] * 1.3, 'Brain efficiency baseline', \n",
    "             ha='right', va='bottom', color='green', fontweight='bold', fontsize=11)\n",
    "    \n",
    "    # Overall title\n",
    "    fig.suptitle('Brain-Inspired Computing is Essential To Avert The Energy Crisis of Modern AI', \n",
    "                 fontsize=18, fontweight='bold', y=1.02)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create and display the comparison\n",
    "fig1 = create_energy_comparison()\n",
    "# fsave = 'figures/energy_comparison.png'\n",
    "# plt.savefig(fsave, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "# print(f\"Plot saved to {fsave}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ae97d",
   "metadata": {},
   "source": [
    "For reference, the \"intelligence\" score in the above-right plot is an average of the following dimensions: \n",
    "\n",
    "| Intelligence Facet       | Human | GPT-3 | GPT-4 | GPT-5 |\n",
    "| ------------------------ | ----- | ----- | ----- | ----- |\n",
    "| **Analytical Reasoning** | 1.0   | ~0.6  | ~0.9  | >1.0  |\n",
    "| **Factual Knowledge** | 1.0   | >1.0  | >1.0  | >1.0  |\n",
    "| **Linguistic Ability** | 1.0   | ~0.8  | ~0.95 | >1.0  |\n",
    "| **Creativity (Ideation)**| 1.0   | ~0.7  | ~0.9  | ~1.0  |\n",
    "| **Emotional Intelligence**| 1.0   | ~0.4  | ~0.6  | ~0.7  |\n",
    "| **Common Sense Reasoning**| 1.0   | ~0.5  | ~0.7  | ~0.8  |\n",
    "| **Embodied Cognition** | 1.0   | 0.0   | 0.0   | 0.0   |\n",
    "\n",
    "These ratios are estimations based on available research and are illustrative at best. The field of AI is evolving rapidly, and these comparisons will change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f516d112",
   "metadata": {},
   "source": [
    "<div style=\"background: #fff5f5; border-left: 4px solid #f56565; padding: 15px; margin: 20px 0;\">\n",
    "    <b>The human brain operates on just 20 watts</b>, whereas global <b>GPT-4 service requires an estimated 20 MW to operate</b>, equivalent to <b>1 million human brains</b>. This immense energy gap is a fundamental challenge to the future of scalable AI.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfabfc",
   "metadata": {},
   "source": [
    "## Part 2: The Exponential Scaling Crisis\n",
    "\n",
    "The energy gap is only part of the problem. For the past decade, AI progress has focused on **bigger models = better performance**. Although this formula has driven remarkable advances, its exponential growth trajectory is approaching physical and economic limits. \n",
    "\n",
    "### The Math\n",
    "\n",
    "The relationship between model size and computational requirements is problematic:\n",
    "- Model sizes double every 6-12 months.\n",
    "- Training energy scaling follows power laws.\n",
    "- Data center capacity and chip manufacturing impose physical constraints on scaling.\n",
    "- Training costs are approaching hundreds of millions of dollars.\n",
    "\n",
    "#### Energy Scaling Laws\n",
    "\n",
    "The relationship between model parameters and energy consumption follows empirical laws (Kaplan et al. 2020):\n",
    "\n",
    "**E = k × N^α**\n",
    "\n",
    "where:\n",
    "- E = Training energy consumption\n",
    "- N = Number of parameters  \n",
    "- α ≈ 1.3 (empirically observed for transformers)\n",
    "- k = Hardware efficiency constant\n",
    "\n",
    "This linear scaling means that **doubling model size requires 2.5x more energy**, and \n",
    "- 10× larger model → 22× more energy\n",
    "- 100× larger model → 500× more energy\n",
    "- Physical limits reached around 10¹³ parameters\n",
    "\n",
    "#### Phyical Constraints\n",
    "\n",
    "##### 1. **Chip Manufacturing Limits**\n",
    "- Current GPU clusters approach reticle limits\n",
    "- Heat dissipation becomes impossible at larger scales\n",
    "- Interconnect bandwidth saturates with system size\n",
    "\n",
    "##### 2. **Power Grid Capacity**\n",
    "- GPT-6 training would require a dedicated power plant\n",
    "- Data centers already strain local electrical infrastructure\n",
    "- Cooling requirements scale non-linearly with power consumption\n",
    "\n",
    "##### 3. **Economic Barriers**\n",
    "- Training costs are growing exponentially: $1M → $100M → $10B\n",
    "- Only ~5 organizations can afford state-of-the-art training\n",
    "- R&D investment are approaching GDP of small nations\n",
    "\n",
    "### Historical Data (2018-2023)\n",
    "\n",
    "| Model | Year | Parameters | Training Energy | Reference |\n",
    "|-------|------|------------|-----------------|-------------------|\n",
    "| **BERT-Large** | 2018 | 340M | ~1 MWh | Strubell et al. 2019 |\n",
    "| **GPT-2** | 2019 | 1.5B | ~10 MWh | OpenAI scaling estimates |\n",
    "| **GPT-3** | 2020 | 175B | 1,287 MWh | Patterson et al. 2021 |\n",
    "| **PaLM** | 2022 | 540B | ~15 GWh | Google Research estimates |\n",
    "| **GPT-4** | 2023 | ~1.8T* | ~50 GWh* | Industry analysis |\n",
    "\n",
    "*Estimated values based on scaling laws\n",
    "\n",
    "### Critical Projections (2025-2027)\n",
    "\n",
    "**Conservative estimates** based on current scaling trends (assuming no fundamental algorithmic breakthroughs) project larger models requiring significantly more resources:\n",
    "\n",
    "- **GPT-5 (2025)**: 10T parameters, 800 GWh training energy\n",
    "- **GPT-6 (2027)**: 100T parameters, 12,000 GWh training energy\n",
    "\n",
    "### Carbon Footprint Analysis\n",
    "\n",
    "Using measured emissions data:\n",
    "\n",
    "| Model | Training Emissions | Equivalent To |\n",
    "|-------|-------------------|---------------|\n",
    "| GPT-3 | 552 tons CO₂ | 120 cars for 1 year |\n",
    "| GPT-4 | ~2,500 tons CO₂ | 540 cars for 1 year |\n",
    "| GPT-5 (proj.) | 40,000 tons CO₂ | 8,700 cars for 1 year |\n",
    "| GPT-6 (proj.) | 600,000 tons CO₂ | 130,000 cars for 1 year |\n",
    "\n",
    "**GPT-6 training would emit more CO₂ than a coal power plant running for 6 months.**\n",
    "\n",
    "### Resource Competition\n",
    "\n",
    "This exponential scaling demands impossible resources:\n",
    "\n",
    "- Requiring 100% of global GPU production for compute power\n",
    "- Consuming entire power plant outputs\n",
    "- Data center cooling approaching municipal supply levels\n",
    "- Exhausting available rare earth elements and global chip manufacturing capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scaling_visualization():\n",
    "    \"\"\"Shows how the energy problem explodes with model size.\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
    "    \n",
    "    # Model scaling data\n",
    "    years = np.array([2018, 2019, 2020, 2022, 2023, 2025, 2027])\n",
    "    model_names = ['BERT', 'GPT-2', 'GPT-3', 'PaLM', 'GPT-4', 'GPT-5*', 'GPT-6*']\n",
    "\n",
    "    # Parameter counts (billions)\n",
    "    parameters = np.array([\n",
    "        0.34,    # BERT-Large: 340M parameters (Devlin et al. 2018)\n",
    "        1.5,     # GPT-2: 1.5B parameters (Radford et al. 2019)\n",
    "        175,     # GPT-3: 175B parameters (Brown et al. 2020)\n",
    "        540,     # PaLM: 540B parameters (Chowdhery et al. 2022)\n",
    "        1800,    # GPT-4: ~1.8T parameters (estimated, OpenAI hasn't disclosed)\n",
    "        10000,   # GPT-5: 10T parameters (projected based on scaling trends)\n",
    "        100000   # GPT-6: 100T parameters (projected, approaching physical limits)\n",
    "    ])\n",
    "    \n",
    "    # Training energy consumption (GWh)\n",
    "    energy_training = np.array([\n",
    "        0.001,   # BERT: ~1 MWh (Strubell et al. 2019, \"Energy and Policy Considerations for Deep Learning in NLP\")\n",
    "        0.01,    # GPT-2: ~10 MWh (estimated from compute requirements)\n",
    "        1.3,     # GPT-3: 1,287 MWh (Patterson et al. 2021, \"Energy and Policy Considerations for Deep Learning in NLP\")\n",
    "        15,      # PaLM: ~15 GWh (estimated from Google's reported compute)\n",
    "        50,      # GPT-4: ~50 GWh (estimated based on training compute and efficiency)\n",
    "        800,     # GPT-5: 800 GWh (projected using E ∝ N^1.3 scaling law)\n",
    "        12000    # GPT-6: 12,000 GWh (exceeds small country consumption)\n",
    "    ])\n",
    "    \n",
    "    # Mark projected vs historical data\n",
    "    projected_mask = np.array([False, False, False, False, False, True, True])\n",
    "\n",
    "    # Create color palette\n",
    "    colors = {\n",
    "        'historical': '#2E86AB',    # Blue for verified data\n",
    "        'projected': '#F24236',     # Red for projections\n",
    "        'crisis': '#FF6B6B',        # Bright red for crisis zones\n",
    "        'warning': '#F18F01',       # Orange for warning zones\n",
    "        'safe': '#4CAF50'           # Green for manageable zones\n",
    "    }\n",
    "    \n",
    "    # Subplot 1: Parameter Growth\n",
    "    ax1.semilogy(years[~projected_mask], parameters[~projected_mask], 'o-', \n",
    "                 color=colors['historical'], linewidth=3, markersize=10, \n",
    "                 label='Historical', alpha=0.9)\n",
    "    ax1.semilogy(years[projected_mask], parameters[projected_mask], 's--', \n",
    "                 color=colors['projected'], linewidth=3, markersize=10, \n",
    "                 label='Projected', alpha=0.9)\n",
    "    \n",
    "    # Add red dashed line connecting historical to projected\n",
    "    last_historical_idx = np.where(~projected_mask)[0][-1]\n",
    "    first_projected_idx = np.where(projected_mask)[0][0]\n",
    "    ax1.plot(\n",
    "        [years[last_historical_idx], years[first_projected_idx]],\n",
    "        [parameters[last_historical_idx], parameters[first_projected_idx]],\n",
    "        '--', color=colors['projected'], linewidth=3, alpha=0.9\n",
    "    )\n",
    "    \n",
    "    # Annotate models\n",
    "    annotation_offsets = [15, -25, 15, -25, 15, -25, 15]\n",
    "    for i, (year, name, param) in enumerate(zip(years, model_names, parameters)):\n",
    "        color = colors['projected'] if projected_mask[i] else colors['historical']\n",
    "        weight = 'bold' if projected_mask[i] else 'normal'\n",
    "        ax1.annotate(name, (year, param), textcoords=\"offset points\", \n",
    "                    xytext=(0, annotation_offsets[i]), ha='center', \n",
    "                    fontsize=10, fontweight=weight, color=color)\n",
    "    \n",
    "    # Add trend line to emphasize exponential growth\n",
    "    z = np.polyfit(years, np.log10(parameters), 1)\n",
    "    trend_line = 10**(z[0] * years + z[1])\n",
    "    ax1.plot(years, trend_line, ':', color='gray', alpha=0.7, linewidth=2, \n",
    "             label=f'Exponential Trend (10^{z[0]:.1f}x per year)')\n",
    "    \n",
    "    ax1.set_xlabel('Year', fontsize=13, fontweight='bold')\n",
    "    ax1.set_ylabel('Parameters (Billions)', fontsize=13, fontweight='bold')\n",
    "    ax1.set_title('Exponential Growth in Model Size', \n",
    "                  fontsize=15, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3, which='both')\n",
    "    ax1.legend(fontsize=11, loc='lower right')\n",
    "    ax1.set_xlim(2017, 2028)\n",
    "    ax1.set_ylim(0.1, 200000)\n",
    "    \n",
    "    # Subplot 2: Energy Crisis Visualization\n",
    "    ax2.semilogy(years[~projected_mask], energy_training[~projected_mask], 'o-', \n",
    "                 color=colors['historical'], linewidth=3, markersize=10, \n",
    "                 label='Historical', alpha=0.9)\n",
    "    ax2.semilogy(years[projected_mask], energy_training[projected_mask], 's--', \n",
    "                 color=colors['projected'], linewidth=3, markersize=10, \n",
    "                 label='Projected', alpha=0.9)\n",
    "    \n",
    "    # Add red dashed line connecting historical to projected\n",
    "    ax2.plot(\n",
    "        [years[last_historical_idx], years[first_projected_idx]],\n",
    "        [energy_training[last_historical_idx], energy_training[first_projected_idx]],\n",
    "        '--', color=colors['projected'], linewidth=3, alpha=0.9\n",
    "    )\n",
    "    \n",
    "    # Add context zones with real-world energy consumption references\n",
    "    ax2.axhspan(1000, 100000, alpha=0.2, color=colors['crisis'], \n",
    "                label='UNSUSTAINABLE (Small Country)')\n",
    "    ax2.axhspan(100, 1000, alpha=0.2, color=colors['warning'], \n",
    "                label='CHALLENGING (Major City)')  \n",
    "    ax2.axhspan(0.0001, 100, alpha=0.2, color=colors['safe'], \n",
    "                label='MANAGEABLE (Data Center)')\n",
    "    \n",
    "    # Add specific energy consumption context labels\n",
    "#     energy_contexts = [\n",
    "#         (2027.2, 15000, 'ENTIRE\\nICELAND\\nANNUAL\\nCONSUMPTION', 'darkred'),\n",
    "#         (2027.2, 500, 'NEW YORK CITY\\nMONTHLY\\nCONSUMPTION', 'darkorange'),\n",
    "#         (2027.2, 10, 'LARGE DATA\\nCENTER\\nCAPACITY', 'darkgreen')\n",
    "#     ]\n",
    "    \n",
    "#     for year, energy, text, color in energy_contexts:\n",
    "#         ax2.text(year, energy, text, fontsize=9, fontweight='bold', \n",
    "#                 color=color, ha='left', va='center',\n",
    "#                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white', \n",
    "#                          edgecolor=color, alpha=0.8))\n",
    "    \n",
    "    ax2.set_xlabel('Year', fontsize=13, fontweight='bold')\n",
    "    ax2.set_ylabel('Training Energy (GWh)', fontsize=13, fontweight='bold')\n",
    "    ax2.set_title('Energy Requirements Approaching Physical Limits', \n",
    "                  fontsize=15, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3, which='both')\n",
    "    ax2.legend(loc='lower right', fontsize=10)\n",
    "    ax2.set_xlim(2017, 2028)\n",
    "    ax2.set_ylim(0.0001, 100000)\n",
    "    \n",
    "    # Add crisis annotation\n",
    "#     ax2.annotate('PHYSICAL\\nLIMITS\\nREACHED', \n",
    "#                 xy=(2027, 12000), xytext=(2024, 40000),\n",
    "#                 arrowprops=dict(arrowstyle='->', color=colors['crisis'], lw=3),\n",
    "#                 fontsize=12, fontweight='bold', color=colors['crisis'],\n",
    "#                 bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', \n",
    "#                          edgecolor=colors['crisis'], alpha=0.9, linewidth=2))\n",
    "    \n",
    "    # Add scaling law to plot\n",
    "    ax2.text(2019, 5000, 'Energy ∝ Parameters^1.3\\n(Empirical Scaling Law)', \n",
    "            fontsize=11, style='italic', \n",
    "            bbox=dict(boxstyle='round,pad=0.4', facecolor='lightblue', alpha=0.7))\n",
    "    \n",
    "    # Main title\n",
    "    fig.suptitle('Current Scaling Trends of AI Model Size and Energy ' +\n",
    "                'Consumption Lead to Impossible Energy Requirements', \n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig2 = create_scaling_visualization()\n",
    "# fsave = 'figures/scaling_crisis.png'\n",
    "# plt.savefig(fsave, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "# print(f\"Plot saved to {fsave}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0c798",
   "metadata": {},
   "source": [
    "## Part 3: Innovation To Avert Energy Crisis\n",
    "\n",
    "Immediate consequences of the energy scaling crisis are all limiting:\n",
    "\n",
    "- Training costs will exclude all but a handful of organizations\n",
    "- Research democratization becomes impossible without efficiency breakthroughs\n",
    "- Carbon regulations may limit AI development in many countries\n",
    "\n",
    "### Sparked Interest In Neuromorphic Computing \n",
    "\n",
    "Taking cues from nature, which has optimized neural networks over millions of years of R&D, researchers have been drawn to **neuromorphic computing**: hardware and algorithms that mimic the brain's energy-efficient information processing. \n",
    "\n",
    "At the heart of this approach are **Spiking Neural Networks (SNNs)**, which process information through discrete spikes rather than continuous activations, and completely change the energy equation:\n",
    "\n",
    "**Traditional Artificial Neural Networks (ANNs)**: Energy ∝ (Number of model parameters)^1.3\n",
    "**Spiking Neural Networks (SNNs)**: Energy ∝ (Spike activity)\n",
    "\n",
    "In SNNs, spiking activity is sparse, i.e. typically only 1-10% of neurons are active at once,similar to the human brain. The brain also shows what's possible:\n",
    "- **20 watts total power consumption**\n",
    "- **86 billion neurons, 100 trillion synapses**\n",
    "- **Equivalent to 10^15 operations/second at 20W**\n",
    "- **10^6 times more efficient than current ANN-based AI systems**\n",
    "\n",
    "The potential efficiency gains over ANNs are possible because SNNs\n",
    "- Process info only when spikes occur\n",
    "- Eliminate unnecessary matrix multiplications\n",
    "- Encode info in spike timing instead of amplitude\n",
    "- Leverage hardware that is optimized for spike processing\n",
    "\n",
    "### Key Differences Between ANNs and SNNs\n",
    "\n",
    "| Aspect | Traditional ANNs | Spiking Neural Networks |\n",
    "|--------|------------------|-------------------------|\n",
    "| **Info Encoding** | Continuous values (0.0 to 1.0) | Binary spikes (0 or 1) |\n",
    "| **Computation** | Matrix multiplications | Event-driven spike processing |\n",
    "| **Hardware** | GPUs/CPUs (power-hungry) | Neuromorphic chips (ultra-low power) |\n",
    "| **Biological Realism** | Abstract mathematical functions | Mimics actual neuron behavior |\n",
    "| **Energy Efficiency** | High power consumption | Orders of magnitude less power |\n",
    "\n",
    "### See It For Yourself\n",
    "\n",
    "In the following, we build an ANN and SNN, process the same visual data through the two different neural networks, and then evaluate their energy consumption in real-time. For each neural network, we'll count actual mathematical operations and convert them to real power consumption. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d45bb33",
   "metadata": {},
   "source": [
    "### Technical Implementation\n",
    "\n",
    "#### Surrogate Gradient Learning for SNNs\n",
    "\n",
    "The biggest challenge in training SNNs is the non-differentiable spike function, which makes standard backpropagation during training impossible. We solve this using surrogate gradients, e.g. a smooth sigmoid derivative, during the backward pass while maintaining exact spike behavior during forward pass. This approach enables learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77347643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateGradientLIF(torch.autograd.Function):\n",
    "    \"\"\"Surrogate gradient for training SNNs.\"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, threshold=1.0):\n",
    "        ctx.save_for_backward(input)\n",
    "        ctx.threshold = threshold\n",
    "        return (input >= threshold).float()\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        alpha = 10.0 # Controls surrogate gradient steepness\n",
    "        # Use sigmoid derivative as smooth approximation\n",
    "        grad = grad_output * alpha * torch.sigmoid(alpha * input) * (1 - torch.sigmoid(alpha * input))\n",
    "        return grad, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945e9a1",
   "metadata": {},
   "source": [
    "#### Biologically-Inspired Spiking Neural Network\n",
    "\n",
    "To finish building out our SNN, we use a Integrate-and-Fire (LIF) neuron model with learnable parameters and biologically-accurate features:\n",
    "\n",
    "- Membrane potential that leaks over time (alpha parameter)\n",
    "- Spike threshold crossing that triggers output spike\n",
    "- Membrane that resets after spiking (beta parameter)\n",
    "- Temporal dynamics across multiple time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bc4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpikingNeuralNet(nn.Module):\n",
    "    \"\"\"Biologically-inspired SNN with training.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=784, hidden_size=128, output_size=10, \n",
    "                 timesteps=10, v_threshold=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Standard linear layers for synaptic connections\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Learnable neuron dynamics parameters\n",
    "        self.alpha = nn.Parameter(torch.ones(1) * 0.9)  # Membrane leak rate\n",
    "        self.beta = nn.Parameter(torch.ones(1) * 0.8)   # Reset strength after spike\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.timesteps = timesteps\n",
    "        self.v_threshold = v_threshold\n",
    "        \n",
    "        # Initialize weights with proper scaling for spiking networks\n",
    "        nn.init.normal_(self.fc1.weight, mean=0, std=np.sqrt(2/input_size))\n",
    "        nn.init.normal_(self.fc2.weight, mean=0, std=np.sqrt(2/hidden_size))\n",
    "        \n",
    "        # Track spike statistics for analysis\n",
    "        self.spike_rates = {'input': 0, 'hidden': 0, 'output': 0}\n",
    "        \n",
    "    def encode_input(self, x):\n",
    "        \"\"\"\n",
    "        Convert static input to temporal spike trains using rate encoding.\n",
    "        Higher pixel intensities → higher spike probability\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        x_normalized = (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    "        \n",
    "        spike_trains = []\n",
    "        for t in range(self.timesteps):\n",
    "            # Add temporal variation to make encoding more realistic\n",
    "            phase = (t / self.timesteps) * 2 * np.pi\n",
    "            rate_modulation = 0.5 + 0.5 * np.sin(phase)\n",
    "            spike_prob = x_normalized * rate_modulation\n",
    "            spikes = torch.bernoulli(spike_prob)\n",
    "            spike_trains.append(spikes)\n",
    "            \n",
    "        return spike_trains\n",
    "    \n",
    "    def forward(self, x, meter=None):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        # Encode input as spike trains\n",
    "        input_spikes = self.encode_input(x)\n",
    "        \n",
    "        # Initialize membrane potentials\n",
    "        v1 = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        v2 = torch.zeros(batch_size, self.output_size, device=x.device)\n",
    "        \n",
    "        # Accumulate output spikes over time\n",
    "        output_spikes = torch.zeros(batch_size, self.output_size, device=x.device)\n",
    "        \n",
    "        # Track total spikes for efficiency analysis\n",
    "        total_input_spikes = 0\n",
    "        total_hidden_spikes = 0\n",
    "        total_output_spikes = 0\n",
    "        \n",
    "        # Process each time step\n",
    "        for t in range(self.timesteps):\n",
    "            # Layer 1: Input → Hidden\n",
    "            h1 = self.fc1(input_spikes[t])\n",
    "            v1 = self.alpha * v1 + h1  # Leaky integration\n",
    "            \n",
    "            # Generate spikes using surrogate gradient\n",
    "            spike_func = SurrogateGradientLIF.apply\n",
    "            spikes1 = spike_func(v1, self.v_threshold)\n",
    "            v1 = v1 * (1 - spikes1) * self.beta  # Reset spiked neurons\n",
    "            \n",
    "            # Layer 2: Hidden → Output\n",
    "            h2 = self.fc2(spikes1)\n",
    "            v2 = self.alpha * v2 + h2\n",
    "            spikes2 = spike_func(v2, self.v_threshold)\n",
    "            v2 = v2 * (1 - spikes2) * self.beta\n",
    "            \n",
    "            output_spikes += spikes2\n",
    "            \n",
    "            # Count spikes for energy analysis\n",
    "            input_spike_count = input_spikes[t].sum().item()\n",
    "            hidden_spike_count = spikes1.sum().item()\n",
    "            output_spike_count = spikes2.sum().item()\n",
    "            \n",
    "            total_input_spikes += input_spike_count\n",
    "            total_hidden_spikes += hidden_spike_count\n",
    "            total_output_spikes += output_spike_count\n",
    "            \n",
    "            # Energy accounting for neuromorphic hardware simulation\n",
    "            if meter:\n",
    "                active_synapses = (\n",
    "                    input_spike_count * self.hidden_size +\n",
    "                    hidden_spike_count * self.output_size\n",
    "                )\n",
    "                \n",
    "                # Memory access for spike storage/routing\n",
    "                memory_bytes = 4 * (input_spike_count + hidden_spike_count + output_spike_count)\n",
    "                \n",
    "                meter.add_operations(\n",
    "                    spikes=input_spike_count + hidden_spike_count + output_spike_count,\n",
    "                    synaptic_ops=active_synapses,\n",
    "                    memory_bytes=memory_bytes\n",
    "                )\n",
    "        \n",
    "        # Calculate network-wide spike rates for analysis\n",
    "        total_neurons = self.input_size + self.hidden_size + self.output_size\n",
    "        total_possible_spikes = total_neurons * self.timesteps * batch_size\n",
    "        actual_spikes = total_input_spikes + total_hidden_spikes + total_output_spikes\n",
    "        \n",
    "        self.spike_rates = {\n",
    "            'input': total_input_spikes / (self.input_size * self.timesteps * batch_size),\n",
    "            'hidden': total_hidden_spikes / (self.hidden_size * self.timesteps * batch_size),\n",
    "            'output': total_output_spikes / (self.output_size * self.timesteps * batch_size),\n",
    "            'overall': actual_spikes / total_possible_spikes\n",
    "        }\n",
    "        \n",
    "        # Return average spike count as network output\n",
    "        return output_spikes / self.timesteps\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512bc19d",
   "metadata": {},
   "source": [
    "### Hardware-Realistic Energy Modeling\n",
    "\n",
    "Our energy model is based on published measurements of NVIDIA's V100 (for our ANN) and Intel's Loihi (SNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007109e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyMeter:\n",
    "    \"\"\"Simulated energy modeling based on published hardware measurements:\n",
    "    - NVIDIA V100: https://images.nvidia.com/content/technologies/volta/pdf/volta-v100-datasheet-update-us-1165301-r5.pdf\n",
    "    - Intel Loihi: Davies et al., \"Loihi: A Neuromorphic Manycore Processor\", IEEE Micro 2018\n",
    "    \n",
    "    These are theoretical calculations, not actual measurements.\n",
    "    Real-world energy consumption varies based on:\n",
    "    - Workload characteristics\n",
    "    - Cooling overhead (adds 30-40%)\n",
    "    - Power delivery efficiency (85-90%)\"\"\"\n",
    "    \n",
    "    def __init__(self, name, device_type='gpu'):\n",
    "        self.name = name\n",
    "        self.device_type = device_type\n",
    "        \n",
    "        if device_type == 'gpu':\n",
    "            # NVIDIA V100 measurements from datasheet\n",
    "            self.joules_per_mac = 4.6e-12         # 4.6 pJ per multiply-accumulate\n",
    "            self.memory_energy_per_byte = 2.6e-9  # HBM2: 2.6 nJ per byte access\n",
    "            self.idle_power = 10.0                # Idle GPU power consumption (W)\n",
    "            self.active_power_multiplier = 15.0   # Active processing power boost\n",
    "            \n",
    "        elif device_type == 'neuromorphic':\n",
    "            # Intel Loihi measurements from research papers\n",
    "            self.joules_per_spike = 23e-12       # 23 pJ per spike event\n",
    "            self.joules_per_synop = 120e-15      # 120 fJ per synaptic operation\n",
    "            self.memory_energy_per_byte = 0.1e-9 # SRAM: 0.1 nJ per byte (much lower than HBM2)\n",
    "            self.idle_power = 0.050              # Loihi idle: 50mW (vs 10W for GPU)\n",
    "            self.active_power_multiplier = 3.0   # Lower power boost for neuromorphic\n",
    "            \n",
    "        self.reset_counters()\n",
    "        \n",
    "    def reset_counters(self):\n",
    "        \"\"\"Reset energy tracking counters\"\"\"\n",
    "        self.total_energy = 0\n",
    "        self.operations = 0\n",
    "        self.memory_bytes = 0\n",
    "        self.instant_power = 0\n",
    "        self.time_elapsed = 0\n",
    "        self.is_active = False\n",
    "        \n",
    "    def add_operations(self, macs=0, spikes=0, synaptic_ops=0, memory_bytes=0):\n",
    "        \"\"\"Add computational operations.\"\"\"\n",
    "        if self.device_type == 'gpu':\n",
    "            self.operations += macs\n",
    "        else: # neuromorphic\n",
    "            self.operations += spikes + synaptic_ops\n",
    "            \n",
    "        self.memory_bytes += memory_bytes\n",
    "        self.is_active = (self.operations > 0)\n",
    "    \n",
    "    def compute_energy(self, dt=0.001):\n",
    "        \"\"\"Calculate realistic energy consumption with activity-dependent power.\n",
    "        Energy = (Static Power) * Time + Dynamic Energy per Operation\n",
    "        \"\"\"\n",
    "        if self.device_type == 'gpu':\n",
    "            # GPU: High static power, high dynamic energy\n",
    "            if self.is_active:\n",
    "                base_power = self.idle_power * self.active_power_multiplier\n",
    "            else:\n",
    "                base_power = self.idle_power\n",
    "                \n",
    "            dynamic_energy = (self.operations * self.joules_per_mac + \n",
    "                            self.memory_bytes * self.memory_energy_per_byte)\n",
    "            static_energy = base_power * dt\n",
    "            \n",
    "        else: # neuromorphic\n",
    "            # Neuromorphic: Very low static power, very low dynamic energy\n",
    "            if self.is_active:\n",
    "                base_power = self.idle_power * self.active_power_multiplier\n",
    "            else:\n",
    "                base_power = self.idle_power\n",
    "                \n",
    "            spike_energy = self.operations * self.joules_per_spike\n",
    "            memory_energy = self.memory_bytes * self.memory_energy_per_byte\n",
    "            static_energy = base_power * dt\n",
    "            dynamic_energy = spike_energy + memory_energy\n",
    "        \n",
    "        frame_energy = dynamic_energy + static_energy\n",
    "        self.total_energy += frame_energy\n",
    "        self.instant_power = frame_energy / dt if dt > 0 else 0\n",
    "        self.time_elapsed += dt\n",
    "        \n",
    "        # Reset per-frame counters\n",
    "        self.operations = 0\n",
    "        self.memory_bytes = 0\n",
    "        self.is_active = False\n",
    "        \n",
    "        return self.instant_power, self.total_energy\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"Return energy metrics.\"\"\"\n",
    "        avg_power = self.total_energy / max(self.time_elapsed, 1e-9)\n",
    "        \n",
    "        # Battery capacity calculation for 3.7V Li-ion battery\n",
    "        battery_voltage = 3.7\n",
    "        mah = (self.total_energy / battery_voltage) / 3.6  # Convert J to mAh\n",
    "        \n",
    "        return {\n",
    "            'total_energy_j': self.total_energy,\n",
    "            'avg_power_w': avg_power,\n",
    "            'instant_power_w': self.instant_power,\n",
    "            'battery_mah': mah,\n",
    "            'time_elapsed_s': self.time_elapsed\n",
    "        }\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75196198",
   "metadata": {},
   "source": [
    "### Real-Time ANN vs SNN Energy Consumption While Processing MNIST Digits\n",
    "\n",
    "The following visualization compares the ANN and SNN hardware across multiple dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE SECTION THAT NEEDS TO BE EDITED\n",
    "\n",
    "def create_metric_card(ax, title, value, unit, color='#667eea'):\n",
    "    \"\"\"Create metric display cards for the dashboard.\"\"\"\n",
    "    ax.clear()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Draw card background with rounded corners\n",
    "    fancy_box = FancyBboxPatch(\n",
    "        (0.05, 0.05), 0.9, 0.9,\n",
    "        boxstyle=\"round,pad=0.03\",\n",
    "        facecolor='#ffffff',\n",
    "        edgecolor=color,\n",
    "        linewidth=2.5,\n",
    "        alpha=0.8\n",
    "    )\n",
    "    ax.add_patch(fancy_box)\n",
    "    \n",
    "    # Add text elements\n",
    "    ax.text(0.5, 0.82, title.upper(), fontsize=9, ha='center', va='center',\n",
    "            color='#495057', fontweight='bold')\n",
    "    ax.text(0.5, 0.5, f\"{value}\", fontsize=14, ha='center', va='center',\n",
    "            color=color, fontweight='bold')\n",
    "    ax.text(0.5, 0.25, unit, fontsize=8, ha='center', va='center',\n",
    "            color='#6c757d')\n",
    "\n",
    "def create_visualization():\n",
    "    \"\"\"Compare ANN vs SNN performance:\n",
    "    1. Input images being processed\n",
    "    2. Network activity patterns\n",
    "    3. Output predictions and accuracy\n",
    "    4. Real-time power consumption\n",
    "    5. Cumulative energy usage\n",
    "    6. Energy efficiency advantage\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load MNIST dataset for demo\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    demo_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Initialize both network types for comparison\n",
    "    ann = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(784, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    ).to(device)\n",
    "    \n",
    "    snn = SpikingNeuralNet(\n",
    "        input_size=784, \n",
    "        hidden_size=128, \n",
    "        output_size=10,\n",
    "        timesteps=10\n",
    "    ).to(device)\n",
    "    \n",
    "    # Quick training phase to ensure meaningful predictions\n",
    "    print(\"Training models for demo...\")\n",
    "    optimizer_ann = torch.optim.Adam(ann.parameters(), lr=0.001)\n",
    "    optimizer_snn = torch.optim.Adam(snn.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=64, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Train both networks briefly (batch_idx below determine loop exit)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx >= 50:\n",
    "            break\n",
    "            \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Train ANN\n",
    "        optimizer_ann.zero_grad()\n",
    "        output_ann = ann(data)\n",
    "        loss_ann = criterion(output_ann, target)\n",
    "        loss_ann.backward()\n",
    "        optimizer_ann.step()\n",
    "        \n",
    "        # Train SNN\n",
    "        optimizer_snn.zero_grad()\n",
    "        output_snn = snn(data)\n",
    "        loss_snn = criterion(output_snn, target)\n",
    "        loss_snn.backward()\n",
    "        optimizer_snn.step()\n",
    "    \n",
    "    print(\"Training complete. Generating animation frames for live comparison...\")\n",
    "    \n",
    "    # Initialize energy meters for both architectures\n",
    "    ann_meter = EnergyMeter(\"ANN\", device_type='gpu')\n",
    "    snn_meter = EnergyMeter(\"SNN\", device_type='neuromorphic')\n",
    "    \n",
    "    # Create dashboard\n",
    "    fig = plt.figure(figsize=(20, 18))\n",
    "    fig.patch.set_facecolor('#f8f9fa')\n",
    "    \n",
    "    # Main title\n",
    "    fig.suptitle(\n",
    "        'Real-Time Energy Comparison: ' +\n",
    "        'Traditional Neural Networks (GPU) vs Spiking Neural Networks (Neuromorphic)',\n",
    "        fontsize=16, fontweight='bold', y=0.98\n",
    "    )\n",
    "    \n",
    "    # Create grid layout for multiple plots\n",
    "    gs = gridspec.GridSpec(10, 6, figure=fig,\n",
    "                          height_ratios=[0.8, 0.8, 0.8, 0.8, 1, 1, 1, 1, 1, 1],\n",
    "                          width_ratios=[1, 1, 1, 1, 1, 1],\n",
    "                          hspace=1.1, wspace=0.5,\n",
    "                          left=0.05, right=0.95, top=0.92, bottom=0.05)\n",
    "\n",
    "    # Define subplot positions\n",
    "    ax_input = fig.add_subplot(gs[1:3, 0])\n",
    "    ax_ann_activity = fig.add_subplot(gs[:2, 1:3])\n",
    "    ax_ann_output = fig.add_subplot(gs[:2, 3:5])\n",
    "    ax_ann_accuracy = fig.add_subplot(gs[:2, 5])\n",
    "    ax_snn_activity = fig.add_subplot(gs[2:4, 1:3])\n",
    "    ax_snn_output = fig.add_subplot(gs[2:4, 3:5])\n",
    "    ax_snn_accuracy = fig.add_subplot(gs[2:4, 5])\n",
    "    ax_power = fig.add_subplot(gs[4:6, :5])    \n",
    "    ax_power_ann_card = fig.add_subplot(gs[4, 5])\n",
    "    ax_power_snn_card = fig.add_subplot(gs[5, 5])\n",
    "    ax_energy = fig.add_subplot(gs[6:8, :5])\n",
    "    ax_energy_ann_card = fig.add_subplot(gs[6, 5])\n",
    "    ax_energy_snn_card = fig.add_subplot(gs[7, 5])\n",
    "    ax_efficiency = fig.add_subplot(gs[8:, :5])\n",
    "    ax_energy_card = fig.add_subplot(gs[8:, 5])\n",
    "    \n",
    "    # Configure input image display\n",
    "    ax_input.set_title('Input Image', fontsize=10, fontweight='bold', pad=5)\n",
    "    ax_input.axis('off')\n",
    "    input_img = ax_input.imshow(np.zeros((28, 28)), cmap='viridis', vmin=-1, vmax=1)\n",
    "    \n",
    "    # Configure network activity displays\n",
    "    ax_ann_activity.set_title('ANN Activity', fontsize=10, fontweight='bold', pad=5)\n",
    "    ax_ann_activity.set_ylim(0, 105)\n",
    "    ax_ann_activity.set_ylabel('Activation Level (%)', fontsize=11, fontweight='bold')\n",
    "    ax_ann_activity.set_xticks([0, 1, 2])\n",
    "    ax_ann_activity.set_xticklabels(['Input', 'Hidden', 'Output'], fontsize=8)\n",
    "    ax_ann_activity.spines['top'].set_visible(False)\n",
    "    ax_ann_activity.spines['right'].set_visible(False)\n",
    "    \n",
    "    ax_snn_activity.set_title('SNN Activity', fontsize=10, fontweight='bold', pad=5)\n",
    "    ax_snn_activity.set_ylim(0, 105)\n",
    "    ax_snn_activity.set_ylabel('Spike Rate (%)', fontsize=11, fontweight='bold')\n",
    "    ax_snn_activity.set_xticks([0, 1, 2])\n",
    "    ax_snn_activity.set_xticklabels(['Input', 'Hidden', 'Output'], fontsize=8)\n",
    "    ax_snn_activity.spines['top'].set_visible(False)\n",
    "    ax_snn_activity.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Initialize activity bar charts\n",
    "    ann_bars = ax_ann_activity.bar([0, 1, 2], [0, 0, 0], color=COLORS['ann'], alpha=0.7)\n",
    "    snn_bars = ax_snn_activity.bar([0, 1, 2], [0, 0, 0], color=COLORS['snn'], alpha=0.7)\n",
    "    \n",
    "    # Configure output prediction displays\n",
    "    ax_ann_output.set_title('Output Predictions', fontsize=10, fontweight='bold', pad=5)\n",
    "    ax_ann_output.set_ylim(0, 1.05)\n",
    "    ax_ann_output.set_ylabel('Confidence', fontsize=9)\n",
    "    ax_ann_output.set_xticks(range(10))\n",
    "    ax_ann_output.set_xticklabels(range(10), fontsize=8)\n",
    "    \n",
    "    ax_snn_output.set_title('Output Predictions', fontsize=10, fontweight='bold', pad=5)\n",
    "    ax_snn_output.set_ylim(0, 1.05)\n",
    "    ax_snn_output.set_ylabel('Confidence', fontsize=9)\n",
    "    ax_snn_output.set_xticks(range(10))\n",
    "    ax_snn_output.set_xticklabels(range(10), fontsize=8)\n",
    "    \n",
    "    ann_output_bars = ax_ann_output.bar(range(10), np.zeros(10), color='salmon', alpha=0.7)\n",
    "    snn_output_bars = ax_snn_output.bar(range(10), np.zeros(10), color='lightgreen', alpha=0.7)\n",
    "    \n",
    "    # Configure power consumption log plot\n",
    "    ax_power.set_title('Instantaneous Power Draw', fontsize=11, fontweight='bold', pad=15)\n",
    "    ax_power.set_xlabel('Time (seconds)', fontsize=9)\n",
    "    ax_power.set_ylabel('Power (W)', fontsize=9)\n",
    "    ax_power.set_xlim(0, 5)\n",
    "    ax_power.set_yscale('log')\n",
    "    ax_power.set_ylim(0.01, 100)\n",
    "    ax_power.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    ann_power_line, = ax_power.plot([], [], 'r-', linewidth=2.5, label='ANN (GPU)', alpha=0.8)\n",
    "    snn_power_line, = ax_power.plot([], [], 'g-', linewidth=2.5, label='SNN (Neuromorphic)', alpha=0.8)\n",
    "    ax_power.legend(loc='upper right', fontsize=9)\n",
    "    \n",
    "    # Configure cumulative energy plot\n",
    "    ax_energy.set_title('Cumulative Energy Consumption', fontsize=11, fontweight='bold', pad=15)\n",
    "    ax_energy.set_xlabel('Time (seconds)', fontsize=9)\n",
    "    ax_energy.set_ylabel('Energy (J)', fontsize=9)\n",
    "    ax_energy.set_xlim(0, 5)\n",
    "    ax_energy.grid(True, alpha=0.3)\n",
    "    \n",
    "    ann_energy_line, = ax_energy.plot([], [], 'r-', linewidth=2.5, label='ANN', alpha=0.8)\n",
    "    snn_energy_line, = ax_energy.plot([], [], 'g-', linewidth=2.5, label='SNN', alpha=0.8)\n",
    "    ax_energy.legend(loc='upper left', fontsize=9)\n",
    "    \n",
    "    # Configure efficiency advantage plot\n",
    "    ax_efficiency.set_title('Energy Efficiency Advantage', fontsize=11, fontweight='bold', pad=15)\n",
    "    ax_efficiency.set_xlabel('Time (seconds)', fontsize=9)\n",
    "    ax_efficiency.set_ylabel('SNN Efficiency Gain (×)', fontsize=9)\n",
    "    ax_efficiency.set_xlim(0, 5)\n",
    "    ax_efficiency.set_ylim(0, 500)\n",
    "    ax_efficiency.grid(True, alpha=0.3)\n",
    "    \n",
    "    efficiency_line, = ax_efficiency.plot([], [], 'b-', linewidth=3, alpha=0.8)\n",
    "    efficiency_fill = None # Will be updated dynamically\n",
    "    ax_efficiency.axhline(y=1, color='gray', linestyle='--', alpha=0.5, label='Break-even')\n",
    "    ax_efficiency.legend(loc='upper left', fontsize=9)\n",
    "    \n",
    "    # Initialize data storage for time series\n",
    "    time_data = []\n",
    "    ann_power_data = []\n",
    "    snn_power_data = []\n",
    "    ann_energy_data = []\n",
    "    snn_energy_data = []\n",
    "    efficiency_data = []\n",
    "    \n",
    "    # Animation state variables\n",
    "    data_iter = iter(demo_loader)\n",
    "    samples_processed = 0\n",
    "    ann_correct = 0\n",
    "    snn_correct = 0\n",
    "    processing_new_sample = False\n",
    "    ann_pred_display = None\n",
    "    snn_pred_display = None\n",
    "    \n",
    "    def animate(frame):\n",
    "        \"\"\"Animation function called for each frame of visualization.\"\"\"\n",
    "        nonlocal data_iter, samples_processed, ann_correct, snn_correct, processing_new_sample\n",
    "        nonlocal efficiency_fill, ann_pred_display, snn_pred_display\n",
    "        \n",
    "        dt = 0.025 # 1/dt FPS\n",
    "        current_time = frame * dt\n",
    "        \n",
    "        # Process new sample every 0.5 seconds\n",
    "        if frame % int(0.5 / dt) == 0:\n",
    "            processing_new_sample = True\n",
    "            \n",
    "            try:\n",
    "                image, label = next(data_iter)\n",
    "            except StopIteration:\n",
    "                data_iter = iter(demo_loader)\n",
    "                image, label = next(data_iter)\n",
    "            \n",
    "            image, label = image.to(device), label.to(device)\n",
    "            \n",
    "            # Run inference with energy tracking\n",
    "            with torch.no_grad():\n",
    "                # ANN inference - traditional approach\n",
    "                ann_output = ann(image)\n",
    "                ann_probs = F.softmax(ann_output, dim=1).squeeze().cpu().numpy()\n",
    "                ann_pred = ann_output.argmax(1).item()\n",
    "                \n",
    "                # Count operations for ANN (matrix multiplications)\n",
    "                ann_meter.add_operations(\n",
    "                    macs=784 * 128 + 128 * 10, # Two dense layer operations\n",
    "                    memory_bytes=4 * (784 + 128 + 10) * 2 # Weight and activation storage\n",
    "                )\n",
    "                \n",
    "                # SNN inference - event-driven\n",
    "                snn_output = snn(image, meter=snn_meter)\n",
    "                snn_probs = F.softmax(snn_output, dim=1).squeeze().cpu().numpy()\n",
    "                snn_pred = snn_output.argmax(1).item()\n",
    "\n",
    "                ann_pred_display = ann_pred\n",
    "                snn_pred_display = snn_pred\n",
    "                \n",
    "                # Track accuracy for both networks\n",
    "                if ann_pred == label.item():\n",
    "                    ann_correct += 1\n",
    "                if snn_pred == label.item():\n",
    "                    snn_correct += 1\n",
    "                    \n",
    "                samples_processed += 1\n",
    "            \n",
    "            # Update input image display\n",
    "            input_img.set_data(image.squeeze().cpu().numpy())\n",
    "            \n",
    "            # Flash ANN activity bars (merely for visual feedback)\n",
    "            ann_bars[0].set_height(100)\n",
    "            ann_bars[0].set_color('#ff6b6b')\n",
    "            ann_bars[1].set_height(100)\n",
    "            ann_bars[1].set_color('#ff6b6b')\n",
    "            ann_bars[2].set_height(100)\n",
    "            ann_bars[2].set_color('#ff6b6b')\n",
    "            \n",
    "            # Update SNN activity with measured spike rates\n",
    "            spike_rates = [\n",
    "                snn.spike_rates['input'] * 100,\n",
    "                snn.spike_rates['hidden'] * 100,\n",
    "                snn.spike_rates['output'] * 100\n",
    "            ]\n",
    "            snn_bars[0].set_height(spike_rates[0])\n",
    "            snn_bars[1].set_height(spike_rates[1])\n",
    "            snn_bars[2].set_height(spike_rates[2])\n",
    "            \n",
    "            # Update output prediction displays with color coding\n",
    "            for i, bar in enumerate(ann_output_bars):\n",
    "                bar.set_height(ann_probs[i])\n",
    "                if i == ann_pred:\n",
    "                    bar.set_color(COLORS['ann'] if ann_pred == label.item() else '#ff9999')\n",
    "                else:\n",
    "                    bar.set_color('salmon')\n",
    "            \n",
    "            for i, bar in enumerate(snn_output_bars):\n",
    "                bar.set_height(snn_probs[i])\n",
    "                if i == snn_pred:\n",
    "                    bar.set_color(COLORS['snn'] if snn_pred == label.item() else '#99ff99')\n",
    "                else:\n",
    "                    bar.set_color('lightgreen')\n",
    "        else:\n",
    "            # Fade ANN activity bars back to normal color (just for visual feedback)\n",
    "            if processing_new_sample:\n",
    "                ann_bars[0].set_color(COLORS['ann'])\n",
    "                ann_bars[1].set_color(COLORS['ann'])\n",
    "                ann_bars[2].set_color(COLORS['ann'])\n",
    "                processing_new_sample = False\n",
    "        \n",
    "        # Update energy measurements for both systems\n",
    "        ann_power, ann_energy = ann_meter.compute_energy(dt)\n",
    "        snn_power, snn_energy = snn_meter.compute_energy(dt)\n",
    "        \n",
    "        # Store time series data\n",
    "        time_data.append(current_time)\n",
    "        ann_power_data.append(ann_power)\n",
    "        snn_power_data.append(snn_power)\n",
    "        ann_energy_data.append(ann_energy)\n",
    "        snn_energy_data.append(snn_energy)\n",
    "        \n",
    "        # Calculate efficiency advantage of SNN compared to ANN\n",
    "        if snn_energy > 1e-12:\n",
    "            efficiency = ann_energy / snn_energy\n",
    "            efficiency_data.append(min(efficiency, 10000)) # Cap for display purposes\n",
    "        else:\n",
    "            efficiency_data.append(0)\n",
    "        \n",
    "        # Update all time series plots\n",
    "        ann_power_line.set_data(time_data, ann_power_data)\n",
    "        snn_power_line.set_data(time_data, snn_power_data)\n",
    "        ann_energy_line.set_data(time_data, ann_energy_data)\n",
    "        snn_energy_line.set_data(time_data, snn_energy_data)\n",
    "        efficiency_line.set_data(time_data, efficiency_data)\n",
    "        \n",
    "        # Update efficiency fill area\n",
    "        if efficiency_fill:\n",
    "            efficiency_fill.remove()\n",
    "        efficiency_fill = ax_efficiency.fill_between(\n",
    "            time_data, 1, efficiency_data, \n",
    "            where=[e > 1 for e in efficiency_data],\n",
    "            color='blue', alpha=0.2\n",
    "        )\n",
    "        \n",
    "        # Dynamic y-axis scaling for energy plot\n",
    "        if len(ann_energy_data) > 0:\n",
    "            max_energy = max(max(ann_energy_data), max(snn_energy_data)) * 1.2\n",
    "            ax_energy.set_ylim(0, max_energy)\n",
    "        \n",
    "        # Update all metric cards with current values\n",
    "        ann_metrics = ann_meter.get_metrics()\n",
    "        snn_metrics = snn_meter.get_metrics()\n",
    "        \n",
    "        # Power consumption cards\n",
    "        create_metric_card(ax_power_ann_card, \"ANN Power\", \n",
    "                         f\"{ann_metrics['instant_power_w']:.1f}\", \"W\", COLORS['ann'])\n",
    "        create_metric_card(ax_power_snn_card, \"SNN Power\",\n",
    "                         f\"{snn_metrics['instant_power_w']*1000:.1f}\", \"mW\", COLORS['snn'])\n",
    "\n",
    "        # Cumulative energy cards\n",
    "        create_metric_card(ax_energy_ann_card, \"ANN Energy\", \n",
    "                         f\"{ann_metrics['total_energy_j']:.2f}\", \"J\", COLORS['ann'])   \n",
    "        create_metric_card(ax_energy_snn_card, \"SNN Energy\",\n",
    "                         f\"{snn_metrics['total_energy_j']*1000:.2f}\", \"mJ\", COLORS['snn'])\n",
    "        \n",
    "        # Energy efficiency advantage card\n",
    "        if len(efficiency_data) > 0 and efficiency_data[-1] > 0:\n",
    "            create_metric_card(ax_energy_card, \"SNN Advantage\",\n",
    "                             f\"{efficiency_data[-1]:.1f}×\", \"less energy\", '#3498db')\n",
    "        \n",
    "        # Accuracy cards with prediction display\n",
    "        if samples_processed > 0:\n",
    "            ann_acc = (ann_correct / samples_processed) * 100\n",
    "            snn_acc = (snn_correct / samples_processed) * 100\n",
    "\n",
    "            ann_unit_text = f\"Predicted: {ann_pred_display}\\nAccuracy: {ann_acc:.0f}%\"\n",
    "            snn_unit_text = f\"Predicted: {snn_pred_display}\\nAccuracy: {snn_acc:.0f}%\"\n",
    "\n",
    "            create_metric_card(ax_ann_accuracy, \"ANN Performance\", \n",
    "                            ann_unit_text, f\"{samples_processed} samples\", COLORS['ann'])\n",
    "            create_metric_card(ax_snn_accuracy, \"SNN Performance\",\n",
    "                            snn_unit_text, f\"{samples_processed} samples\", COLORS['snn'])\n",
    "        \n",
    "        return [ann_power_line, snn_power_line, ann_energy_line, snn_energy_line,\n",
    "                efficiency_line, input_img] + list(ann_bars) + list(snn_bars) + \\\n",
    "               list(ann_output_bars) + list(snn_output_bars)\n",
    "    \n",
    "    # Create and return animation\n",
    "    anim = FuncAnimation(fig, animate, frames=1000, interval=25, blit=False)\n",
    "    \n",
    "    return fig, anim\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "#     # Create and display the energy comparison\n",
    "#     fig, anim = create_visualization()\n",
    "    \n",
    "#     # For Jupyter/Colab\n",
    "#     display(HTML(anim.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa11760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualization():\n",
    "    \"\"\"Compare ANN vs SNN energy and accuracy performances:\n",
    "    1. Input images being processed\n",
    "    2. Network activity patterns\n",
    "    3. Output predictions and accuracy\n",
    "    4. Real-time power consumption\n",
    "    5. Cumulative energy usage\n",
    "    6. Energy efficiency advantage\n",
    "    \"\"\"\n",
    "    \n",
    "    DEMO_CONFIG = {\n",
    "        'n_samples': 50,            # Number of MNIST samples to process\n",
    "        'training_batches': 200,   # Pre-training iterations (more = better accuracy)\n",
    "        'animation_speed': 100,    # ms per frame (lower = faster)\n",
    "        'timesteps': 20,            # SNN temporal resolution\n",
    "        'sample_interval': 20,     # Frames between new samples\n",
    "    }\n",
    "    \n",
    "    # Load MNIST dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST(\n",
    "        root='./data', train=True, download=True, transform=transform\n",
    "    )\n",
    "    \n",
    "    demo_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Initialize networks with better architecture\n",
    "    ann = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(784, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(128, 10)\n",
    "    ).to(device)\n",
    "    \n",
    "    snn = SpikingNeuralNet(\n",
    "        input_size=784, \n",
    "        hidden_size=256, \n",
    "        output_size=10,\n",
    "        timesteps=DEMO_CONFIG['timesteps']\n",
    "    ).to(device)\n",
    "    \n",
    "    print(\"Training networks for meaningful predictions...\")\n",
    "    optimizer_ann = torch.optim.Adam(ann.parameters(), lr=0.001)\n",
    "    optimizer_snn = torch.optim.Adam(snn.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=64, shuffle=True\n",
    "    )\n",
    "    \n",
    "    # Training loop with progress\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx >= DEMO_CONFIG['training_batches']:\n",
    "            break\n",
    "            \n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f\"   Batch {batch_idx}/{DEMO_CONFIG['training_batches']}\")\n",
    "            \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Train ANN\n",
    "        optimizer_ann.zero_grad()\n",
    "        output_ann = ann(data)\n",
    "        loss_ann = criterion(output_ann, target)\n",
    "        loss_ann.backward()\n",
    "        optimizer_ann.step()\n",
    "        \n",
    "        # Train SNN\n",
    "        optimizer_snn.zero_grad()\n",
    "        output_snn = snn(data)\n",
    "        loss_snn = criterion(output_snn, target)\n",
    "        loss_snn.backward()\n",
    "        optimizer_snn.step()\n",
    "    \n",
    "    print(\"Training complete. Now calculating energy consumption...\")\n",
    "    \n",
    "    # Animation with improved layout\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    fig.patch.set_facecolor(\"#f8f9fa\")\n",
    "\n",
    "    fig.suptitle(\n",
    "        'Real-Time Neural Network Comparison: Traditional AI vs Brain-Inspired AI',\n",
    "        fontsize=20, fontweight='bold', y=0.96, color='#2c3e50')\n",
    "\n",
    "    # Improved gridspec with dedicated flow row at top\n",
    "    gs = gridspec.GridSpec(4, 8, figure=fig,\n",
    "                          height_ratios=[0.4, 1.2, 1.2, 0.4],\n",
    "                          width_ratios=[1.0, 0.18, 1.5, 0.18, 1.5, 0.18, 1.0, 0.1],\n",
    "                          hspace=0.35, wspace=0.18,\n",
    "                          left=0.06, right=0.94, top=0.92, bottom=0.08)        \n",
    "    \n",
    "    # Input image (spans both ANN/SNN rows for visual prominence)\n",
    "    ax_input = fig.add_subplot(gs[1:3, 0])\n",
    "    ax_input.set_title('Input Digit', fontsize=16, fontweight='bold', pad=15, color='#34495e')\n",
    "    ax_input.axis('off')\n",
    "    input_img = ax_input.imshow(np.zeros((28, 28)), cmap='gray', vmin=-1, vmax=1)\n",
    "\n",
    "    # Network activity comparison - same width as prediction plots\n",
    "    ax_ann_activity = fig.add_subplot(gs[1, 2])\n",
    "    ax_ann_activity.set_title('ANN Activity Pattern', fontsize=13, fontweight='bold', \n",
    "                             color=COLORS['ann'], pad=12)\n",
    "    ax_ann_activity.set_ylabel('Layer Activity (%)', fontsize=11)\n",
    "    ax_ann_activity.set_ylim(0, 100)\n",
    "    ax_ann_activity.set_xticks([0, 1, 2])\n",
    "    ax_ann_activity.set_xticklabels(['Input', 'Hidden', 'Output'], fontsize=10)\n",
    "    ax_ann_activity.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax_snn_activity = fig.add_subplot(gs[2, 2])\n",
    "    ax_snn_activity.set_title('SNN Spike Pattern', fontsize=13, fontweight='bold', \n",
    "                             color=COLORS['snn'], pad=12)\n",
    "    ax_snn_activity.set_ylabel('Spike Rate (%)', fontsize=11)\n",
    "    ax_snn_activity.set_ylim(0, 100)\n",
    "    ax_snn_activity.set_xticks([0, 1, 2])\n",
    "    ax_snn_activity.set_xticklabels(['Input', 'Hidden', 'Output'], fontsize=10)\n",
    "    ax_snn_activity.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Prediction displays - same width as activity plots\n",
    "    ax_ann_pred = fig.add_subplot(gs[1, 4])\n",
    "    ax_ann_pred.set_title('ANN Prediction', fontsize=13, fontweight='bold', \n",
    "                         color=COLORS['ann'], pad=12)\n",
    "    ax_ann_pred.set_ylabel('Confidence', fontsize=11)\n",
    "    ax_ann_pred.set_ylim(0, 1)\n",
    "    ax_ann_pred.set_xticks(range(10))\n",
    "    ax_ann_pred.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax_snn_pred = fig.add_subplot(gs[2, 4])\n",
    "    ax_snn_pred.set_title('SNN Prediction', fontsize=13, fontweight='bold', \n",
    "                         color=COLORS['snn'], pad=12)\n",
    "    ax_snn_pred.set_ylabel('Confidence', fontsize=11)\n",
    "    ax_snn_pred.set_ylim(0, 1)\n",
    "    ax_snn_pred.set_xticks(range(10))\n",
    "    ax_snn_pred.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Large digit display for predictions\n",
    "    ax_ann_digit = fig.add_subplot(gs[1, 6])\n",
    "    ax_ann_digit.set_title('ANN Guess', fontsize=13, fontweight='bold', pad=12, color='#34495e')\n",
    "    ax_ann_digit.axis('off')\n",
    "    \n",
    "    ax_snn_digit = fig.add_subplot(gs[2, 6])\n",
    "    ax_snn_digit.set_title('SNN Guess', fontsize=13, fontweight='bold', pad=12, color='#34495e') \n",
    "    ax_snn_digit.axis('off')\n",
    "    \n",
    "    # Status bar for current sample info\n",
    "    ax_status = fig.add_subplot(gs[3, :])\n",
    "    ax_status.axis('off')\n",
    "\n",
    "    # Style improvements for all axes\n",
    "    for ax in (ax_ann_activity, ax_snn_activity, ax_ann_pred, ax_snn_pred):\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_color('#bdc3c7')\n",
    "        ax.spines['bottom'].set_color('#bdc3c7')\n",
    "        ax.tick_params(colors='#34495e', labelsize=9)\n",
    "    \n",
    "    # Initialize visualization elements\n",
    "    ann_bars = ax_ann_activity.bar([0, 1, 2], [0, 0, 0], color=COLORS['ann'], alpha=0.8, width=0.6)\n",
    "    snn_bars = ax_snn_activity.bar([0, 1, 2], [0, 0, 0], color=COLORS['snn'], alpha=0.8, width=0.6)\n",
    "    ann_pred_bars = ax_ann_pred.bar(range(10), np.zeros(10), color=COLORS['ann'], alpha=0.8, width=0.7)\n",
    "    snn_pred_bars = ax_snn_pred.bar(range(10), np.zeros(10), color=COLORS['snn'], alpha=0.8, width=0.7)\n",
    "\n",
    "    # Create flow diagram in top row\n",
    "    ax_flow = fig.add_subplot(gs[0, :])\n",
    "    ax_flow.set_axis_off()\n",
    "    \n",
    "    # Flow elements with proper alignment to columns below\n",
    "    flow_axes   = [ax_input, ax_ann_activity, ax_ann_pred, ax_ann_digit]\n",
    "    flow_labels = ['Input Digit', 'Processor Activity', 'Analyze Predictions', 'Output Digit']\n",
    "    flow_colors = ['#34495e', '#7f8c8d', '#3498db', \"#b587e9\"]\n",
    "    \n",
    "    # Vertical band (within the top row area) for the flow boxes\n",
    "    flow_bbox = ax_flow.get_position()           # figure coords (0..1)\n",
    "    y0 = flow_bbox.y0 + 0.18*flow_bbox.height    # a bit of top/bottom padding\n",
    "    y1 = flow_bbox.y1 - 0.18*flow_bbox.height\n",
    "    h  = y1 - y0\n",
    "\n",
    "    rects_xyw = []\n",
    "    for ax in flow_axes:\n",
    "        bb = ax.get_position()                   # figure coords for each target axis\n",
    "        x, w = bb.x0, bb.width                   # use *exact* width & left edge\n",
    "        rects_xyw.append((x, w))\n",
    "\n",
    "    # Draw boxes, labels, and arrows in figure coordinates for perfect alignment\n",
    "    for i, ((x, w), label, color) in enumerate(zip(rects_xyw, flow_labels, flow_colors)):\n",
    "        rect = Rectangle((x, y0), w, h,\n",
    "                        transform=fig.transFigure,  # <- figure coords\n",
    "                        facecolor=color, alpha=0.15,\n",
    "                        edgecolor=color, linewidth=2, zorder=10)\n",
    "        fig.add_artist(rect)\n",
    "\n",
    "        fig.text(x + w/2, y0 + h/2, label,\n",
    "                transform=fig.transFigure,\n",
    "                ha='center', va='center', fontsize=11, fontweight='bold',\n",
    "                color=color, zorder=11)\n",
    "\n",
    "        if i < len(rects_xyw) - 1:\n",
    "            x_next, _ = rects_xyw[i+1]\n",
    "            arrow = FancyArrowPatch((x + w, y0 + h/2), (x_next, y0 + h/2),\n",
    "                                    transform=fig.transFigure,\n",
    "                                    arrowstyle='-|>', linewidth=2.5,\n",
    "                                    mutation_scale=10, mutation_aspect=1.1,\n",
    "                                    color='#2c3e50', alpha=0.7, zorder=12)\n",
    "            fig.add_artist(arrow)\n",
    "    \n",
    "    # Initialize energy tracking\n",
    "    ann_meter = EnergyMeter(\"ANN\", device_type='gpu')\n",
    "    snn_meter = EnergyMeter(\"SNN\", device_type='neuromorphic')\n",
    "    \n",
    "    # Data collection for static plots\n",
    "    analysis_data = {\n",
    "        'samples': [],\n",
    "        'ann_predictions': [],\n",
    "        'snn_predictions': [],\n",
    "        'true_labels': [],\n",
    "        'ann_energy': [],\n",
    "        'snn_energy': [],\n",
    "        'ann_power': [],\n",
    "        'snn_power': [],\n",
    "        'snn_spike_rates': [],\n",
    "        'processing_times': []\n",
    "    }\n",
    "    \n",
    "    # Animation state\n",
    "    data_iter = iter(demo_loader)\n",
    "    samples_processed = 0\n",
    "    current_image = None\n",
    "    current_label = None\n",
    "    \n",
    "    def animate(frame):\n",
    "        nonlocal data_iter, samples_processed, current_image, current_label\n",
    "        \n",
    "        # Process new sample at intervals\n",
    "        if frame % DEMO_CONFIG['sample_interval'] == 0 and samples_processed < DEMO_CONFIG['n_samples']:\n",
    "            \n",
    "            try:\n",
    "                current_image, current_label = next(data_iter)\n",
    "            except StopIteration:\n",
    "                data_iter = iter(demo_loader)\n",
    "                current_image, current_label = next(data_iter)\n",
    "            \n",
    "            current_image, current_label = current_image.to(device), current_label.to(device)\n",
    "            \n",
    "            # Update input display\n",
    "            input_img.set_data(current_image.squeeze().cpu().numpy())\n",
    "            \n",
    "            # Run inference\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                # ANN inference\n",
    "                ann_output = ann(current_image)\n",
    "                ann_probs = F.softmax(ann_output, dim=1).squeeze().cpu().numpy()\n",
    "                ann_pred = ann_output.argmax(1).item()\n",
    "                \n",
    "                # ANN energy\n",
    "                ann_meter.add_operations(\n",
    "                    macs=784 * 256 + 256 * 128 + 128 * 10,\n",
    "                    memory_bytes=4 * (784 + 256 + 128 + 10) * 2\n",
    "                )\n",
    "                ann_power, ann_energy = ann_meter.compute_energy(0.001)\n",
    "                \n",
    "                # SNN inference\n",
    "                snn_output = snn(current_image, meter=snn_meter)\n",
    "                snn_probs = F.softmax(snn_output, dim=1).squeeze().cpu().numpy()\n",
    "                snn_pred = snn_output.argmax(1).item()\n",
    "\n",
    "                # SNN energy\n",
    "                snn_power, snn_energy = snn_meter.compute_energy(0.001)\n",
    "                \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            # Store data for plots\n",
    "            analysis_data['samples'].append(samples_processed)\n",
    "            analysis_data['ann_predictions'].append(ann_pred)\n",
    "            analysis_data['snn_predictions'].append(snn_pred)\n",
    "            analysis_data['true_labels'].append(current_label.item())\n",
    "            analysis_data['ann_energy'].append(ann_energy * 1000) # Convert to mJ\n",
    "            analysis_data['snn_energy'].append(snn_energy * 1000) # Convert to mJ\n",
    "            analysis_data['ann_power'].append(ann_power)\n",
    "            analysis_data['snn_power'].append(snn_power)\n",
    "            analysis_data['snn_spike_rates'].append(snn.spike_rates.get('overall', 0))\n",
    "            analysis_data['processing_times'].append(processing_time)\n",
    "            \n",
    "            # Update activity displays\n",
    "            # ANN: Estimate realistic activity heights for dense computation\n",
    "            input_activity = (current_image.squeeze() > 0).float().mean().item() * 100\n",
    "            hidden_activity = 50 + np.random.normal(0, 5) # ~50% after ReLU\n",
    "            output_activity = 100 # All output neurons active\n",
    "            \n",
    "            ann_bars[0].set_height(input_activity)\n",
    "            ann_bars[1].set_height(hidden_activity) \n",
    "            ann_bars[2].set_height(output_activity)\n",
    "            for bar in ann_bars:\n",
    "                bar.set_color(COLORS['ann'])\n",
    "                bar.set_alpha(0.8)\n",
    "                \n",
    "            # SNN: Show actual sparse activity\n",
    "            spike_rates = [\n",
    "                snn.spike_rates.get('input', 0) * 100,\n",
    "                snn.spike_rates.get('hidden', 0) * 100,\n",
    "                snn.spike_rates.get('output', 0) * 100\n",
    "            ]\n",
    "            for i, bar in enumerate(snn_bars):\n",
    "                bar.set_height(spike_rates[i])\n",
    "                bar.set_alpha(0.8)\n",
    "            \n",
    "            # Update prediction displays\n",
    "            for i, (ann_bar, snn_bar) in enumerate(zip(ann_pred_bars, snn_pred_bars)):\n",
    "                ann_bar.set_height(ann_probs[i])\n",
    "                snn_bar.set_height(snn_probs[i])\n",
    "                \n",
    "                # Highlight most likely prediction\n",
    "                ann_color = COLORS['ann'] if i == ann_pred else '#ffb3b3'\n",
    "                snn_color = COLORS['snn'] if i == snn_pred else '#b3ffb3'\n",
    "                ann_bar.set_color(ann_color)\n",
    "                snn_bar.set_color(snn_color)\n",
    "                ann_bar.set_alpha(0.9 if i == ann_pred else 0.4)\n",
    "                snn_bar.set_alpha(0.9 if i == snn_pred else 0.4)\n",
    "            \n",
    "            # Display predicted digits\n",
    "            ax_ann_digit.clear()\n",
    "            ax_ann_digit.text(0.5, 0.5, str(ann_pred), fontsize=60, \n",
    "                             fontweight='bold', ha='center', va='center',\n",
    "                             color=COLORS['ann'] if ann_pred == current_label.item() else '#ffb3b3')\n",
    "            ax_ann_digit.set_xlim(0, 1)\n",
    "            ax_ann_digit.set_ylim(0, 1)\n",
    "            ax_ann_digit.axis('off')\n",
    "            \n",
    "            ax_snn_digit.clear()\n",
    "            ax_snn_digit.text(0.5, 0.5, str(snn_pred), fontsize=60,\n",
    "                             fontweight='bold', ha='center', va='center', \n",
    "                             color=COLORS['snn'] if snn_pred == current_label.item() else '#b3ffb3')\n",
    "            ax_snn_digit.set_xlim(0, 1)\n",
    "            ax_snn_digit.set_ylim(0, 1)\n",
    "            ax_snn_digit.axis('off')\n",
    "            \n",
    "            # Update status\n",
    "            ax_status.clear()\n",
    "            status_text = (f\"Sample {samples_processed + 1}/{DEMO_CONFIG['n_samples']} | \"\n",
    "                          f\"True Label: {current_label.item()} | \"\n",
    "                          f\"ANN: {ann_pred} {'✓' if ann_pred == current_label.item() else '✗'} | \"\n",
    "                          f\"SNN: {snn_pred} {'✓' if snn_pred == current_label.item() else '✗'} | \"\n",
    "                          f\"Energy Ratio: {ann_energy/max(snn_energy, 1e-12):.0f}:1\")\n",
    "            \n",
    "            ax_status.text(0.5, 0.5, status_text,\n",
    "                          ha='center', va='center', fontsize=13, \n",
    "                          fontweight='bold', color='#2c3e50')\n",
    "            ax_status.set_xlim(0, 1)\n",
    "            ax_status.set_ylim(0, 1)\n",
    "            ax_status.axis('off')            \n",
    "            \n",
    "            samples_processed += 1\n",
    "            \n",
    "        return []\n",
    "    \n",
    "    # Create animation\n",
    "    frames = DEMO_CONFIG['sample_interval'] * DEMO_CONFIG['n_samples'] + 20\n",
    "    anim = FuncAnimation(fig, animate, frames=frames, \n",
    "                        interval=DEMO_CONFIG['animation_speed'], blit=False)\n",
    "    \n",
    "    return fig, anim, analysis_data\n",
    "\n",
    "def create_static_analysis(analysis_data):    \n",
    "    if len(analysis_data['samples']) == 0:\n",
    "        print(\"No data collected for analysis\")\n",
    "        return None\n",
    "    \n",
    "    fig, ((ax1, ax2, ax3, ax4)) = plt.subplots(4, 1, figsize=(8, 14))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    # fig.suptitle('Traditional AI (ANN) vs Brain-Inspired AI (SNN)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Calculate running accuracy metrics\n",
    "    ann_running_accuracy = []\n",
    "    snn_running_accuracy = []\n",
    "    \n",
    "    ann_correct_count = 0\n",
    "    snn_correct_count = 0\n",
    "    \n",
    "    for i, (ann_pred, snn_pred, true_label) in enumerate(zip(\n",
    "        analysis_data['ann_predictions'], \n",
    "        analysis_data['snn_predictions'], \n",
    "        analysis_data['true_labels'])):\n",
    "        \n",
    "        if ann_pred == true_label:\n",
    "            ann_correct_count += 1\n",
    "        if snn_pred == true_label:\n",
    "            snn_correct_count += 1\n",
    "            \n",
    "        # Running accuracy = correct so far / samples so far\n",
    "        ann_running_accuracy.append((ann_correct_count / (i + 1)) * 100)\n",
    "        snn_running_accuracy.append((snn_correct_count / (i + 1)) * 100)\n",
    "    \n",
    "    final_ann_accuracy = ann_running_accuracy[-1] if ann_running_accuracy else 0\n",
    "    final_snn_accuracy = snn_running_accuracy[-1] if snn_running_accuracy else 0\n",
    "    \n",
    "    total_ann_energy = sum(analysis_data['ann_energy'])\n",
    "    total_snn_energy = sum(analysis_data['snn_energy'])\n",
    "    energy_ratio = total_ann_energy / max(total_snn_energy, 1e-9)\n",
    "    \n",
    "    # 1. Running Accuracy Comparison\n",
    "    ax1.plot(analysis_data['samples'], ann_running_accuracy, \n",
    "            'r-', linewidth=2, label=f'ANN (Final: {final_ann_accuracy:.1f}%)')\n",
    "    ax1.plot(analysis_data['samples'], snn_running_accuracy, \n",
    "            'g-', linewidth=2, label=f'SNN (Final: {final_snn_accuracy:.1f}%)')\n",
    "    ax1.set_xlabel('Sample Number')\n",
    "    ax1.set_ylabel('Running Accuracy (%)')\n",
    "    ax1.set_title('Classification Accuracy Over Time')\n",
    "    ax1.set_ylim(0, 105)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Energy Consumption Over Time\n",
    "    ax2.plot(analysis_data['samples'], np.cumsum(analysis_data['ann_energy']), \n",
    "            'r-', linewidth=2, label='ANN')\n",
    "    ax2.plot(analysis_data['samples'], np.cumsum(analysis_data['snn_energy']), \n",
    "            'g-', linewidth=2, label='SNN')\n",
    "    ax2.set_xlabel('Sample Number')\n",
    "    ax2.set_ylabel('Cumulative Energy (mJ)')\n",
    "    ax2.set_title('Energy Consumption Over Time')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Power Draw Comparison\n",
    "    ax3.plot(analysis_data['samples'], analysis_data['ann_power'], \n",
    "            'r-', alpha=0.7, label='ANN')\n",
    "    ax3.plot(analysis_data['samples'], np.array(analysis_data['snn_power']), \n",
    "            'g-', alpha=0.7, label='SNN')\n",
    "    ax3.set_xlabel('Sample Number') \n",
    "    ax3.set_ylabel('Power (W)')\n",
    "    ax3.set_title('Instantaneous Power Draw')\n",
    "    ax3.set_yscale('log')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Efficiency Advantage\n",
    "    efficiency_ratios = [a/max(s, 1e-12) for a, s in \n",
    "                        zip(analysis_data['ann_energy'], analysis_data['snn_energy'])]\n",
    "    ax4.plot(analysis_data['samples'], efficiency_ratios, 'b-', linewidth=2)\n",
    "    # ax4.axhline(y=1, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax4.set_xlabel('Sample Number')\n",
    "    ax4.set_ylabel('Energy Efficiency (ANN/SNN)')\n",
    "    ax4.set_title(f'SNN Efficiency Advantage (Avg: {np.mean(efficiency_ratios):.0f}×)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    xmin, xmax = analysis_data['samples'][0], analysis_data['samples'][-1]\n",
    "\n",
    "    for ax in (ax1, ax2, ax3, ax4):\n",
    "        ax.set_title(ax.get_title(), pad=8)\n",
    "        ax.xaxis.labelpad = 6\n",
    "        ax.yaxis.labelpad = 6\n",
    "        ax.set_xlim(xmin, xmax+0.5)\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(nbins=8, integer=True, prune='both'))\n",
    "        ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
    "\n",
    "    plt.tight_layout() \n",
    "    \n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fig_anim, anim, data = create_visualization()\n",
    "    \n",
    "    display(HTML(anim.to_jshtml()))\n",
    "    \n",
    "    fig_static = create_static_analysis(data)\n",
    "    if fig_static:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67d9101",
   "metadata": {},
   "source": [
    "## Part 4: SNNs Are A Promising Alternative To ANNs\n",
    "\n",
    "This visualization demonstrates that **SNNs can use >100× less energy** than dense ANNs while maintaining competitive accuracy.\n",
    "\n",
    "In addition to significantly reducing the carbon footprint of AI systems, the improved efficiency of SNNs is especially critical for deploying AI on battery-powered devices or always-on sensors and for achieving real-time / low-latency processing for robotics and autonomous systems. \n",
    "\n",
    "### The Biological Inspiration\n",
    "\n",
    "The dramatic improvement in energy efficiency is achieved through **sparse activity, event-driven processing, and temporal dynamics**. \n",
    "\n",
    "| **Aspect** | **Traditional ANNs** | **Brain-Inspired SNNs** | **Impact** |\n",
    "|------------|---------------------|------------------------|------------|\n",
    "| **Information Encoding** | Continuous values (0.0-1.0) | Binary spikes over time | 10× less data movement |\n",
    "| **Computation Model** | Synchronous matrix operations | Asynchronous event processing | 100× fewer operations |\n",
    "| **Activity Pattern** | ~50% neurons always active | ~5% neurons fire when needed | 10× less power draw |\n",
    "| **Hardware Utilization** | Constant high power draw | Power scales with activity | Days vs. hours of battery |\n",
    "| **Biological Fidelity** | Mathematical abstraction | Mimics actual neurons | Future-proof design |\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 25px; border-radius: 15px; margin: 25px 0; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
    "    <h3 style=\"color: white; margin: 0; font-size: 24px;\">The Biological Blueprint</h3>\n",
    "    <p style=\"color: white; margin: 15px 0; font-size: 16px; line-height: 1.6;\">\n",
    "        Biological neurons fire only when necessary, amounting to 1-5% of the time. This sparse activity pattern achieves the brain's extraordinary efficiency. By mimicking this principle, Spiking Neural Networks (SNNs) achieve significant energy savings while maintaining computational accuracy.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "### Seeing Sparsity in Action\n",
    "\n",
    "The following code block shows how sparse, event-driven computation achieves these efficiency gains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c72b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_activity_visualization():\n",
    "    \"\"\"Compare dense ANN and sparse SNN computation patterns with real energy measurements.\"\"\"\n",
    "\n",
    "    # Run actual inference to get real metrics\n",
    "    print(\"Computing real energy metrics...\")\n",
    "    \n",
    "    # Prepare test data\n",
    "    test_batch = torch.randn(32, 1, 28, 28).to(device)\n",
    "    \n",
    "    # Initialize networks\n",
    "    ann_model = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(784, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    ).to(device)\n",
    "    \n",
    "    snn_model = SpikingNeuralNet(\n",
    "        input_size=784, \n",
    "        hidden_size=256, \n",
    "        output_size=10, \n",
    "        timesteps=10\n",
    "    ).to(device)\n",
    "    \n",
    "    # Measure energy consumption\n",
    "    ann_meter = EnergyMeter(\"ANN\", device_type='gpu')\n",
    "    snn_meter = EnergyMeter(\"SNN\", device_type='neuromorphic')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        # ANN forward pass\n",
    "        ann_output = ann_model(test_batch)\n",
    "        ann_meter.add_operations(\n",
    "            macs=32 * (784*256 + 256*128 + 128*10),  # Batch size * layer operations\n",
    "            memory_bytes=4 * 32 * (784 + 256 + 128 + 10) * 2\n",
    "        )\n",
    "        _, ann_energy_j = ann_meter.compute_energy(0.001)\n",
    "        \n",
    "        # SNN forward pass\n",
    "        snn_output = snn_model(test_batch, meter=snn_meter)\n",
    "        _, snn_energy_j = snn_meter.compute_energy(0.001)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    ann_energy_mj = ann_energy_j * 1000\n",
    "    snn_energy_mj = snn_energy_j * 1000\n",
    "    efficiency_gain = ann_energy_mj / max(snn_energy_mj, 1e-9) # Avoid divide by zero\n",
    "    snn_sparsity = 100 - (snn_model.spike_rates.get('overall', 0.05) * 100)\n",
    "    \n",
    "    # Set up figure and grid layout\n",
    "    fig = plt.figure(figsize=(14, 14))\n",
    "    fig.patch.set_facecolor('#f8f9fa')\n",
    "\n",
    "    gs = gridspec.GridSpec(\n",
    "        3, 2, \n",
    "        figure=fig,\n",
    "        height_ratios=[1.5, 1.5, 1.0],\n",
    "        width_ratios=[1, 1],\n",
    "        hspace=0.35, \n",
    "        wspace=0.25,\n",
    "        left=0.06, right=0.94, top=0.90, bottom=0.05\n",
    "    )\n",
    "    \n",
    "    # Main title\n",
    "    fig.suptitle(\n",
    "        f\"Sparse Activity Is Key To {efficiency_gain:.0f}× Better Energy Efficiency\",\n",
    "        fontsize=22, fontweight='bold', y=0.98\n",
    "    )\n",
    "    \n",
    "    # Subtitle for context\n",
    "    fig.text(0.5, 0.94, \n",
    "             'Comparison of traditional AI (ANNs) vs. brain-inspired AI (SNNs)',\n",
    "             ha='center', fontsize=14, style='italic', color='#555')\n",
    "    \n",
    "    # ANN Activity Heatmap\n",
    "    ax_ann_activity = fig.add_subplot(gs[0, 0])\n",
    "    \n",
    "    # Generate realistic ANN activity\n",
    "    np.random.seed(42)\n",
    "    neurons_per_layer = 30\n",
    "    time_steps = 20\n",
    "    \n",
    "    # ANN: Dense activity (~50% active after ReLU)\n",
    "    ann_activity = np.random.beta(2, 2, (neurons_per_layer, time_steps))\n",
    "    ann_activity = (ann_activity > 0.5).astype(float) * np.random.uniform(0.3, 1.0, (neurons_per_layer, time_steps))\n",
    "    \n",
    "    im_ann = ax_ann_activity.imshow(\n",
    "        ann_activity, \n",
    "        aspect='auto', \n",
    "        cmap='hot',\n",
    "        interpolation='nearest',\n",
    "        vmin=0, vmax=1\n",
    "    )\n",
    "    \n",
    "    ax_ann_activity.set_title('Traditional ANN: Dense Activity', \n",
    "                              fontsize=14, fontweight='bold', color=COLORS['ann'], pad=10)\n",
    "    ax_ann_activity.set_xlabel('Time Steps', fontsize=11)\n",
    "    ax_ann_activity.set_ylabel('Neurons', fontsize=11)\n",
    "    \n",
    "    # Add activity percentage annotation\n",
    "    ann_active_pct = (ann_activity > 0.01).mean() * 100\n",
    "    ax_ann_activity.text(0.98, 0.98, f'{ann_active_pct:.0f}% Active', \n",
    "                         transform=ax_ann_activity.transAxes,\n",
    "                         ha='right', va='top',\n",
    "                         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                         fontsize=12, fontweight='bold', color=COLORS['ann'])\n",
    "    \n",
    "    # Colorbar for ANN\n",
    "    cbar_ann = plt.colorbar(im_ann, ax=ax_ann_activity, fraction=0.046, pad=0.04)\n",
    "    cbar_ann.set_label('Activation Level', fontsize=10)\n",
    "    \n",
    "    # SNN Spike Raster\n",
    "    ax_snn_activity = fig.add_subplot(gs[0, 1])\n",
    "    \n",
    "    # SNN: Sparse spikes (~5% active)\n",
    "    snn_spikes = np.random.random((neurons_per_layer, time_steps)) < 0.05\n",
    "    \n",
    "    # Create visually distinct spikes\n",
    "    spike_display = np.zeros((neurons_per_layer, time_steps, 3))\n",
    "    spike_positions = np.where(snn_spikes)\n",
    "    \n",
    "    for i, j in zip(spike_positions[0], spike_positions[1]):\n",
    "        spike_display[i, j] = [1, 0.8, 0] # Yellow spikes\n",
    "    \n",
    "    ax_snn_activity.imshow(spike_display, aspect='auto', interpolation='nearest')\n",
    "    \n",
    "    # Add spike markers for clarity\n",
    "    for i, j in zip(spike_positions[0], spike_positions[1]):\n",
    "        ax_snn_activity.plot(j, i, 'o', color='yellow', markersize=4, \n",
    "                            markeredgecolor='orange', markeredgewidth=0.5)\n",
    "    \n",
    "    ax_snn_activity.set_title('Brain-Inspired SNN: Sparse Spikes', \n",
    "                              fontsize=14, fontweight='bold', color=COLORS['snn'], pad=10)\n",
    "    ax_snn_activity.set_xlabel('Time Steps', fontsize=11)\n",
    "    ax_snn_activity.set_ylabel('Neurons', fontsize=11)\n",
    "    ax_snn_activity.set_facecolor('#1a1a1a')\n",
    "    \n",
    "    # Add sparsity annotation\n",
    "    snn_active_pct = snn_spikes.mean() * 100\n",
    "    ax_snn_activity.text(0.98, 0.98, f'{snn_active_pct:.1f}% Active', \n",
    "                         transform=ax_snn_activity.transAxes,\n",
    "                         ha='right', va='top',\n",
    "                         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                         fontsize=12, fontweight='bold', color=COLORS['snn'])\n",
    "    \n",
    "    # Energy comparison\n",
    "    ax_energy = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    # Create bar chart\n",
    "    categories = ['Per\\nInference', 'Per\\nSecond', 'Per\\nHour']\n",
    "    ann_values = [ann_energy_mj, ann_energy_mj*1000, ann_energy_mj*3600000]\n",
    "    snn_values = [snn_energy_mj, snn_energy_mj*1000, snn_energy_mj*3600000]\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars_ann = ax_energy.bar(x - width/2, ann_values, width, \n",
    "                             label='ANN', color=COLORS['ann'], \n",
    "                             alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    bars_snn = ax_energy.bar(x + width/2, snn_values, width,\n",
    "                             label='SNN', color=COLORS['snn'],\n",
    "                             alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add labels\n",
    "    for bars in [bars_ann, bars_snn]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 1000000:\n",
    "                label = f'{height/1000000:.1f}J'\n",
    "            elif height > 1000:\n",
    "                label = f'{height/1000:.1f}mJ'\n",
    "            else:\n",
    "                label = f'{height:.2f}mJ'\n",
    "            \n",
    "            ax_energy.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                          label, ha='center', va='bottom',\n",
    "                          fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax_energy.set_yscale('log')\n",
    "    ax_energy.set_ylabel('Energy Consumption', fontsize=11)\n",
    "    ax_energy.set_title('Energy Usage Comparison', fontsize=14, fontweight='bold', pad=10)\n",
    "    ax_energy.set_xticks(x)\n",
    "    ax_energy.set_xticklabels(categories)\n",
    "    ax_energy.legend(loc='upper left', fontsize=11)\n",
    "    ax_energy.grid(True, alpha=0.3, axis='y', which='both')\n",
    "    \n",
    "    # Activity Distribution\n",
    "    ax_distribution = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    # Calculate per-neuron activity stats\n",
    "    ann_per_neuron = (ann_activity > 0.01).mean(axis=1) * 100\n",
    "    snn_per_neuron = snn_spikes.mean(axis=1) * 100\n",
    "    \n",
    "    # Create overlapping histograms\n",
    "    bins = np.linspace(0, max(ann_per_neuron.max(), 20), 15)\n",
    "    \n",
    "    ax_distribution.hist(ann_per_neuron, bins=bins, alpha=0.6, \n",
    "                        color=COLORS['ann'], edgecolor='black',\n",
    "                        label=f'ANN (μ={ann_per_neuron.mean():.0f}%)', \n",
    "                        linewidth=1.5)\n",
    "    ax_distribution.hist(snn_per_neuron, bins=bins, alpha=0.6,\n",
    "                        color=COLORS['snn'], edgecolor='black', \n",
    "                        label=f'SNN (μ={snn_per_neuron.mean():.1f}%)',\n",
    "                        linewidth=1.5)\n",
    "    \n",
    "    ax_distribution.set_xlabel('Activity Rate (%)', fontsize=11)\n",
    "    ax_distribution.set_ylabel('Number of Neurons', fontsize=11)\n",
    "    ax_distribution.set_title('Activity Distribution', fontsize=14, fontweight='bold', pad=10)\n",
    "    ax_distribution.legend(loc='upper right', fontsize=10)\n",
    "    ax_distribution.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add annotation about bimodal vs uniform distribution\n",
    "    ax_distribution.axvline(x=50, color='red', linestyle='--', alpha=0.3, linewidth=2)\n",
    "    ax_distribution.axvline(x=5, color='green', linestyle='--', alpha=0.3, linewidth=2)\n",
    "    \n",
    "    # Scaling projection\n",
    "    ax_scaling = fig.add_subplot(gs[2, :])\n",
    "    \n",
    "    model_sizes = np.logspace(0, 4, 50) # 1 to 10,000 relative size\n",
    "    ann_energy_scaling = model_sizes ** 1.3 # Empirical scaling\n",
    "    snn_energy_scaling = model_sizes ** 0.8 # Better scaling with sparsity\n",
    "    \n",
    "    ax_scaling.loglog(model_sizes, ann_energy_scaling, '-',\n",
    "                     color=COLORS['ann'], linewidth=3, label='ANN: O(n^1.3)')\n",
    "    ax_scaling.loglog(model_sizes, snn_energy_scaling, '-',\n",
    "                     color=COLORS['snn'], linewidth=3, label='SNN: O(n^0.8)')\n",
    "    \n",
    "    # Fill the gap to hilite advantage\n",
    "    ax_scaling.fill_between(model_sizes, ann_energy_scaling, snn_energy_scaling,\n",
    "                           where=(ann_energy_scaling > snn_energy_scaling),\n",
    "                           alpha=0.2, color='green', label='Energy Saved')\n",
    "    \n",
    "    # Denote current and future model sizes\n",
    "    current_size = 1000\n",
    "    future_size = 10000\n",
    "    \n",
    "    ax_scaling.scatter([current_size], [current_size**1.3], s=100, color=COLORS['ann'],\n",
    "                      marker='o', zorder=5, edgecolor='black', linewidth=2)\n",
    "    ax_scaling.scatter([current_size], [current_size**0.8], s=100, color=COLORS['snn'],\n",
    "                      marker='o', zorder=5, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Add annotations for gap at scale\n",
    "    gap_current = current_size**1.3 / current_size**0.8\n",
    "    gap_future = future_size**1.3 / future_size**0.8\n",
    "    \n",
    "    ax_scaling.annotate(f'{gap_current:.0f}× gap', \n",
    "                       xy=(current_size, current_size**1.05),\n",
    "                       xytext=(current_size*2, current_size**1.1),\n",
    "                       arrowprops=dict(arrowstyle='->', color='black', lw=1.5),\n",
    "                       fontsize=11, fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "    \n",
    "    ax_scaling.set_xlabel('Model Size (relative)', fontsize=11)\n",
    "    ax_scaling.set_ylabel('Energy Consumption (relative)', fontsize=11)\n",
    "    ax_scaling.set_title('Energy Scaling Gap Widens with Model Size', \n",
    "                        fontsize=14, fontweight='bold', pad=10)\n",
    "    ax_scaling.legend(loc='upper left', fontsize=10)\n",
    "    ax_scaling.grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Return fig and metrics for subsequent use\n",
    "    metrics_dict = {\n",
    "        'ann_energy_mj': ann_energy_mj,\n",
    "        'snn_energy_mj': snn_energy_mj,\n",
    "        'efficiency_gain': efficiency_gain,\n",
    "        'ann_activity': ann_active_pct,\n",
    "        'snn_activity': snn_active_pct,\n",
    "        'snn_sparsity': snn_sparsity\n",
    "    }\n",
    "    \n",
    "    return fig, metrics_dict\n",
    "\n",
    "fig_comprehensive, sparsity_metrics = create_sparse_activity_visualization()\n",
    "plt.show()\n",
    "\n",
    "# print(\"\\n📊 Sparsity Analysis Complete:\")\n",
    "# print(f\"   • ANN Activity: {sparsity_metrics['ann_activity']:.1f}%\")\n",
    "# print(f\"   • SNN Activity: {sparsity_metrics['snn_activity']:.1f}%\") \n",
    "# print(f\"   • Efficiency Gain: {sparsity_metrics['efficiency_gain']:.0f}×\")\n",
    "# print(f\"   • Energy Saved: {(1 - sparsity_metrics['snn_energy_mj']/sparsity_metrics['ann_energy_mj'])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be8056",
   "metadata": {},
   "source": [
    "## A Paradigm Shift in AI Computing\n",
    "\n",
    "We've demonstrated that brain-inspired computing (SNNs) achieves comparable accuracy as traditional AI (ANNs) while reducing energy consumption by TBD-TBD×. This improvement is one promising solution to the energy crisis facing AI development.\n",
    "\n",
    "### The Implications Are Exciting\n",
    "\n",
    "1. Today, SNNs can be deployed immediately on existing hardware with **10-100× efficiency gains**\n",
    "2. Tomorrow, neuromorphic chips may achieve >1000× improvements\n",
    "3. SNNs makes AGI-scale models **more environmentally and economically viable**\n",
    "4. Viability enables sophisticated AI on edge devices and in developing regions\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #667eea, #764ba2); padding: 2px; border-radius: 10px; margin: 20px 0;\">\n",
    "    <div style=\"background: white; border-radius: 8px; padding: 20px;\">\n",
    "        <h4 style=\"color: #667eea; margin-top: 0;\">Coming in Notebook 2: The Biological Blueprint</h4>\n",
    "        <p style=\"color: #4a5568; line-height: 1.8;\">\n",
    "            We'll analyze real neural recordings (from my Ph.D. research in Donhee Ham's group at Harvard) to understand how biological neurons achieve such remarkable efficiency.\n",
    "        </p>\n",
    "        <p style=\"color: #667eea; font-weight: bold; margin-top: 15px;\">\n",
    "            Preview: TBD\n",
    "        </p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "**Brain-Inspired AI Series**  \n",
    "**[Part 1: The Energy Crisis ✓]** | [Part 2: Biological Blueprint →](link) | [Part 3: Mathematics →](link) | [Part 4: Implementation →](link) | [Part 5: Deployment →](link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
